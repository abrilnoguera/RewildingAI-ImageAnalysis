{"cells":[{"cell_type":"markdown","metadata":{"id":"9QgWy64mefKs"},"source":["Para replicar el referenciamiento de ImageNet en tu propio dataset de imágenes almacenado en Amazon S3 y ejecutar la transferencia de aprendizaje con VGG16, debes seguir varios pasos. Aquí tienes una guía general sobre cómo hacerlo:\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"--MGqE0-ejHh"},"outputs":[],"source":["# Librerías estándar\n","import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from io import BytesIO\n","\n","# TensorFlow y Keras\n","import tensorflow as tf\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import (Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D, MaxPooling2D, Reshape)\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n","\n","# Otras librerías\n","import os\n","import boto3\n","from PIL import Image\n","from sklearn.metrics import (accuracy_score, auc, average_precision_score, classification_report,\n","                             confusion_matrix, precision_score, recall_score)\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"SilxVuzGcn4e"},"source":["# Entrenamiento Animal y No Animal"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"k2NXUxbkcn4e"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('ArchivosUtiles/trainingAnimal.pkl')\n","test = pd.read_pickle('ArchivosUtiles/testingAnimal.pkl')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xaXOJxH9cn4e"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Animal']\n","X_test = test['Imagen']\n","y_test = test['Animal']"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"rVp6rm74cn4e"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{"id":"XMnvI64Nf_sQ"},"source":["## Descarga del modelo VGG16 pre-entrenado:\n","Descarga el modelo VGG16 pre-entrenado con pesos de ImageNet. Puedes hacerlo utilizando TensorFlow o Keras."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"XJTxGKtGgdz1"},"outputs":[],"source":["input_shape = (150, 150, 3)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"BIgdNTQTgfgs"},"outputs":[],"source":["# Carga el modelo VGG16 preentrenado con pesos de ImageNet (no incluye las capas densas superiores)\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"]},{"cell_type":"markdown","metadata":{"id":"V6GuJ5YOgNHW"},"source":["## Generador de datos:\n","\n","Utiliza un generador de datos de Keras para cargar y preprocesar tus imágenes desde S3. Debes proporcionar la ruta a tus imágenes en S3 y etiquetas correspondientes. Aquí un ejemplo de cómo configurar un generador de datos:"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"7Sk25YR_kb8U"},"outputs":[],"source":["# Número de clases en tu conjunto de datos\n","num_classes = len(y_train.unique())"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"IL-a9_xbkvZn"},"outputs":[],"source":["# Tamaño del lote (batch size) que deseas utilizar durante el entrenamiento\n","batch_size = 32"]},{"cell_type":"markdown","metadata":{"id":"LpvkgxD3cn4g"},"source":["## Entrenamiento del modelo:\n","\n","Añade capas personalizadas en la parte superior del modelo VGG16 y entrena el modelo en tus datos utilizando el generador de datos. Asegúrate de congelar las capas base de VGG16 para que no se actualicen durante el entrenamiento."]},{"cell_type":"code","execution_count":39,"metadata":{"id":"CD74A8wCcn4g"},"outputs":[],"source":["# Agregar capas personalizadas en la parte superior del modelo base\n","x = Flatten()(base_model.output) #Flatten output to 1 dimension\n","\n","# # Agregar más capas densas\n","x = Dense(1024, activation='relu')(x)  # Añade una capa con Relu activation\n","x = Dropout(0.2)(x)  # Añade un dropout rate de 0.2\n","\n","predictions = Dense(1, activation = 'sigmoid')(x)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"BrlcuY_mcn4g"},"outputs":[],"source":["# Crear el modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"CcZSIgh9cn4h"},"outputs":[],"source":["# Congelar las capas del modelo base para el transfer learning\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"bHbMQBbpcn4h"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n","WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"]}],"source":["# Compilar el modelo\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"5c-f-G3Hcn4h"},"outputs":[],"source":["# Define the EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=5,           # Number of epochs with no improvement after which training will be stopped\n","    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",")"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"mPR7VFsNcn4i"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","151/151 [==============================] - 208s 1s/step - loss: 2.4253 - accuracy: 0.9534 - val_loss: 3.1730 - val_accuracy: 0.9338\n","Epoch 2/30\n","151/151 [==============================] - 199s 1s/step - loss: 1.5477 - accuracy: 0.9716 - val_loss: 3.4536 - val_accuracy: 0.9346\n","Epoch 3/30\n","151/151 [==============================] - 205s 1s/step - loss: 0.6468 - accuracy: 0.9727 - val_loss: 2.8843 - val_accuracy: 0.9421\n","Epoch 4/30\n","151/151 [==============================] - 204s 1s/step - loss: 0.8646 - accuracy: 0.9735 - val_loss: 2.8375 - val_accuracy: 0.9338\n","Epoch 5/30\n","151/151 [==============================] - 209s 1s/step - loss: 0.8134 - accuracy: 0.9756 - val_loss: 2.5009 - val_accuracy: 0.9371\n","Epoch 6/30\n","151/151 [==============================] - 206s 1s/step - loss: 0.7724 - accuracy: 0.9764 - val_loss: 2.2056 - val_accuracy: 0.9421\n","Epoch 7/30\n","151/151 [==============================] - 210s 1s/step - loss: 0.5277 - accuracy: 0.9812 - val_loss: 2.2880 - val_accuracy: 0.9379\n","Epoch 8/30\n","151/151 [==============================] - 203s 1s/step - loss: 0.5178 - accuracy: 0.9791 - val_loss: 2.2924 - val_accuracy: 0.9379\n","Epoch 9/30\n","151/151 [==============================] - 205s 1s/step - loss: 0.4646 - accuracy: 0.9816 - val_loss: 2.1649 - val_accuracy: 0.9445\n","Epoch 10/30\n","151/151 [==============================] - 200s 1s/step - loss: 0.4491 - accuracy: 0.9818 - val_loss: 2.4685 - val_accuracy: 0.9454\n","Epoch 11/30\n","151/151 [==============================] - 214s 1s/step - loss: 0.3546 - accuracy: 0.9810 - val_loss: 2.4707 - val_accuracy: 0.9396\n","Epoch 12/30\n","151/151 [==============================] - 205s 1s/step - loss: 0.4100 - accuracy: 0.9816 - val_loss: 2.3607 - val_accuracy: 0.9412\n","Epoch 13/30\n","151/151 [==============================] - 205s 1s/step - loss: 0.2156 - accuracy: 0.9820 - val_loss: 2.1888 - val_accuracy: 0.9371\n","Epoch 14/30\n","151/151 [==============================] - 199s 1s/step - loss: 0.3548 - accuracy: 0.9863 - val_loss: 1.9102 - val_accuracy: 0.9445\n","Epoch 15/30\n","151/151 [==============================] - 208s 1s/step - loss: 0.1446 - accuracy: 0.9876 - val_loss: 2.0438 - val_accuracy: 0.9462\n","Epoch 16/30\n","151/151 [==============================] - 206s 1s/step - loss: 0.1514 - accuracy: 0.9853 - val_loss: 2.0899 - val_accuracy: 0.9346\n","Epoch 17/30\n","151/151 [==============================] - 216s 1s/step - loss: 0.4343 - accuracy: 0.9857 - val_loss: 2.0947 - val_accuracy: 0.9371\n","Epoch 18/30\n","151/151 [==============================] - 226s 1s/step - loss: 0.2427 - accuracy: 0.9843 - val_loss: 3.1748 - val_accuracy: 0.9404\n","Epoch 19/30\n","151/151 [==============================] - 224s 1s/step - loss: 0.1921 - accuracy: 0.9851 - val_loss: 3.1935 - val_accuracy: 0.9412\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x28f54a550>"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["# Entrena el modelo con los datos de entrenamiento\n","model.fit(X_train_tf, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"w2NsNXwtcn4i"},"outputs":[],"source":["# Guardar el modelo entrenado\n","model.save('ModelosFinales/modeloAnimalVGG16_v2.h5')"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"8L6vW1wWcn4j","outputId":"ed9d69a1-af32-45c1-9720-a766db10b1ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["48/48 [==============================] - 57s 1s/step\n"]}],"source":["y_proba = model.predict(X_test_tf)\n","y_pred = (y_proba >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"z30PY8nLcn4j","outputId":"a10da620-0e63-42f5-f8a6-d10b2a3bc6f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9456953642384106\n","Recall: 0.9614890885750963\n","Specificity: 0.9288645690834473\n"]}],"source":["# Calculamos Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Calculamos Recall\n","recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Recall: {recall}\")\n","\n","# Calculamos Specificity\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","specificity = tn / (tn + fp)\n","print(f\"Specificity: {specificity}\")\n","\n","# Accuracy: 0.9696714406065712\n","# Recall: 0.9854838709677419\n","# Specificity: 0.9523809523809523\n","\n","# Accuracy: 0.9337748344370861\n","# Recall: 0.9396662387676509\n","# Specificity: 0.9274965800273598"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"RI46LS2Acn4k","outputId":"8b2409c4-fd1d-42a1-8085-811bd8841917"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision (AP): 0.9728555826424565\n"]}],"source":["# Calcular average precision\n","ap = average_precision_score(y_test, y_proba)\n","\n","print(\"Average Precision (AP):\", ap)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Za6vMqCCcn4k","outputId":"ff12b0d8-c471-48cf-f5b0-d76fe5b7d5c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.94      0.93      0.93       731\n","           1       0.93      0.94      0.94       779\n","\n","    accuracy                           0.93      1510\n","   macro avg       0.93      0.93      0.93      1510\n","weighted avg       0.93      0.93      0.93      1510\n","\n"]}],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"J0IgauQCcn4l"},"source":["# Entrenamiento Guanaco y No Guanaco"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"8N0g-ZY5cn4l"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('ArchivosUtiles/trainingGuanaco.pkl')\n","test = pd.read_pickle('ArchivosUtiles/testingGuanaco.pkl')"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"MLkzZqP4cn4l"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Guanaco']\n","X_test = test['Imagen']\n","y_test = test['Guanaco']"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"15bqeJA_cn4v"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{"id":"uJPIz6-4cn4w"},"source":["## Balanceo"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"WpEMtRrbcn4w","outputId":"baf9c258-3298-4497-85c5-00f9adbabb92"},"outputs":[{"data":{"text/plain":["Guanaco\n","1.0    1786\n","0.0    1061\n","Name: count, dtype: int64"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["y_train.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"5oi8oQWPcn4w"},"source":["La base esta desbalanceada ya que existen muchos mas guanacos que otros animales. Para resolver esto se somete al resto de los animales a tecnicas de *Data Augmentation*"]},{"cell_type":"markdown","metadata":{"id":"RZZYJ2DRcn4x"},"source":["Data Augmentation: make training set larger by applying transformations. More information to learn from.\n","- Brightness and Contrast adjustments\n","- Rotations\n","- Gaussian noise\n","- Mirroring"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"XG4EE2FMcn4x"},"outputs":[],"source":["def data_augmentation(image_tensor):\n","\n","    # Convierte el tensor de imagen a una imagen TensorFlow\n","    image = tf.convert_to_tensor(image_tensor, dtype=tf.float32)\n","\n","    # Brightness and Contrast adjustments\n","    if np.random.rand() < 0.8:\n","        image = tf.image.adjust_brightness(image, delta=0.2)  # Cambiar el brillo\n","        image = tf.image.adjust_contrast(image, contrast_factor=1.2)  # Cambiar el contraste\n","\n","    # Rotations\n","    if np.random.rand() < 0.7:\n","        degrees = np.random.uniform(-10, 10)  # Rotación aleatoria entre -10 y 10 grados\n","        degrees = int(round(degrees))  # Redondea los grados a un entero\n","        image = tf.image.rot90(image, k=degrees // 90)  # Rotar la imagen\n","\n","    # Gaussian noise\n","    if np.random.rand() < 0.2:\n","        noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.1)\n","        image = image + noise\n","\n","    # Mirroring (flip horizontal)\n","    if np.random.rand() < 0.5:\n","        image = tf.image.flip_left_right(image)\n","\n","    # Convierte la imagen aumentada de nuevo a un tensor\n","    augmented_image_tensor = tf.convert_to_tensor(image.numpy(), dtype=tf.float32)\n","\n","    return augmented_image_tensor"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"8HvJo8COcn4x"},"outputs":[],"source":["# Crea una nueva lista para almacenar los tensores de imágenes aumentados\n","imagen_tensor_aumentada = []\n","\n","# Itera a través de las filas del DataFrame y aplica la función de aumento de datos\n","for index, row in train.iterrows():\n","    if np.random.rand() < 0.38:\n","        imagen_tensor = row['Imagen']\n","        imagen_aumentada = data_augmentation(imagen_tensor)\n","        imagen_tensor_aumentada.append(imagen_aumentada)"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"SdMZMqFYcn4y"},"outputs":[],"source":["train_augmentation = pd.DataFrame(columns=['Imagen', 'Guanaco'])\n","train_augmentation['Imagen'] = imagen_tensor_aumentada\n","train_augmentation['Guanaco'] = False"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"an0ZqnQlcn4y"},"outputs":[],"source":["train_augmentation= pd.concat([train, train_augmentation], ignore_index=True)"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"WJdtoeLjcn4y","outputId":"61ad4588-7888-4209-cf5d-2e95e7470c6a"},"outputs":[{"data":{"text/plain":["Guanaco\n","0.0    2141\n","1.0    1786\n","Name: count, dtype: int64"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["train_augmentation['Guanaco'].value_counts()"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"ABm-6-S9cn4y"},"outputs":[],"source":["X_train = train_augmentation['Imagen']\n","y_train = train_augmentation['Guanaco']"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"fLCtpmGFcn4z"},"outputs":[],"source":["X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))"]},{"cell_type":"markdown","metadata":{"id":"Hf6BXZehcn4z"},"source":["## Descarga del modelo VGG16 pre-entrenado:\n","Descarga el modelo VGG16 pre-entrenado con pesos de ImageNet. Puedes hacerlo utilizando TensorFlow o Keras."]},{"cell_type":"code","execution_count":87,"metadata":{"id":"tbJiADgVcn4z"},"outputs":[],"source":["input_shape = (150, 150, 3)"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"FCNve5CScn4z"},"outputs":[],"source":["# Carga el modelo VGG16 preentrenado con pesos de ImageNet (no incluye las capas densas superiores)\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"]},{"cell_type":"markdown","metadata":{"id":"dquYhTIllN48"},"source":["## Entrenamiento del modelo:\n","\n","Añade capas personalizadas en la parte superior del modelo VGG16 y entrena el modelo en tus datos utilizando el generador de datos. Asegúrate de congelar las capas base de VGG16 para que no se actualicen durante el entrenamiento."]},{"cell_type":"code","execution_count":111,"metadata":{"id":"wiUDCsHmcn40"},"outputs":[],"source":["# Agregar capas personalizadas en la parte superior del modelo base\n","x = Flatten()(base_model.output)  # Flatten output to 1 dimension\n","\n","# # Agregar más capas densas\n","# x = Dense(1024, activation='relu')(x)  # Añade una capa con Relu activation\n","# x = Dropout(0.2)(x)  # Añade un dropout rate de 0.2\n","\n","# # Agregar más capas densas\n","# x = Dense(512, activation='relu')(x)\n","# x = Dropout(0.3)(x)\n","\n","# # Agregar más capas densas\n","# x = Dense(256, activation='relu')(x)\n","# x = Dropout(0.2)(x)\n","\n","# # Agregar más capas densas\n","# x = Dense(128, activation='relu')(x)\n","# x = Dropout(0.2)(x)\n","\n","# Capa de salida\n","predictions = Dense(1, activation='sigmoid')(x)"]},{"cell_type":"code","execution_count":112,"metadata":{"id":"MXs_FglPcn40"},"outputs":[],"source":["# Crear el modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":113,"metadata":{"id":"C54GZI5Scn40"},"outputs":[],"source":["# Congelar las capas del modelo base para el transfer learning\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":114,"metadata":{"id":"o-M7fJNtcn40"},"outputs":[],"source":["# Define the EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=5,           # Number of epochs with no improvement after which training will be stopped\n","    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",")"]},{"cell_type":"code","execution_count":118,"metadata":{"id":"6A_yt6kBcn41"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n","WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"]}],"source":["# Compilar el modelo\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[],"source":["y_train = y_train.astype('float32')\n","y_test = y_test.astype('float32')"]},{"cell_type":"code","execution_count":120,"metadata":{"id":"-6mxEqjTcn41","outputId":"f623eb48-2298-4b17-a9db-0fc41c56527b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","72/72 [==============================] - 146s 2s/step - loss: 2.1579 - accuracy: 0.6671 - val_loss: 1.5966 - val_accuracy: 0.6842\n","Epoch 2/30\n","72/72 [==============================] - 157s 2s/step - loss: 1.2139 - accuracy: 0.7519 - val_loss: 1.2077 - val_accuracy: 0.7193\n","Epoch 3/30\n","72/72 [==============================] - 168s 2s/step - loss: 0.8786 - accuracy: 0.7949 - val_loss: 1.0568 - val_accuracy: 0.7561\n","Epoch 4/30\n","72/72 [==============================] - 177s 2s/step - loss: 0.6680 - accuracy: 0.8274 - val_loss: 0.9972 - val_accuracy: 0.7632\n","Epoch 5/30\n","72/72 [==============================] - 138s 2s/step - loss: 0.5341 - accuracy: 0.8480 - val_loss: 0.8893 - val_accuracy: 0.7860\n","Epoch 6/30\n","72/72 [==============================] - 147s 2s/step - loss: 0.4234 - accuracy: 0.8704 - val_loss: 0.8472 - val_accuracy: 0.8000\n","Epoch 7/30\n","72/72 [==============================] - 162s 2s/step - loss: 0.3553 - accuracy: 0.8880 - val_loss: 0.8098 - val_accuracy: 0.8123\n","Epoch 8/30\n","72/72 [==============================] - 98s 1s/step - loss: 0.2906 - accuracy: 0.9012 - val_loss: 0.7965 - val_accuracy: 0.8123\n","Epoch 9/30\n","72/72 [==============================] - 94s 1s/step - loss: 0.2401 - accuracy: 0.9209 - val_loss: 0.7791 - val_accuracy: 0.8228\n","Epoch 10/30\n","72/72 [==============================] - 97s 1s/step - loss: 0.2088 - accuracy: 0.9337 - val_loss: 0.7628 - val_accuracy: 0.8263\n","Epoch 11/30\n","72/72 [==============================] - 103s 1s/step - loss: 0.1794 - accuracy: 0.9429 - val_loss: 0.7449 - val_accuracy: 0.8281\n","Epoch 12/30\n","72/72 [==============================] - 100s 1s/step - loss: 0.1582 - accuracy: 0.9495 - val_loss: 0.7607 - val_accuracy: 0.8140\n","Epoch 13/30\n","72/72 [==============================] - 99s 1s/step - loss: 0.1412 - accuracy: 0.9530 - val_loss: 0.7387 - val_accuracy: 0.8316\n","Epoch 14/30\n","72/72 [==============================] - 99s 1s/step - loss: 0.1176 - accuracy: 0.9649 - val_loss: 0.7341 - val_accuracy: 0.8439\n","Epoch 15/30\n","72/72 [==============================] - 96s 1s/step - loss: 0.1083 - accuracy: 0.9671 - val_loss: 0.7194 - val_accuracy: 0.8368\n","Epoch 16/30\n","72/72 [==============================] - 96s 1s/step - loss: 0.0979 - accuracy: 0.9719 - val_loss: 0.7203 - val_accuracy: 0.8404\n","Epoch 17/30\n","72/72 [==============================] - 99s 1s/step - loss: 0.0889 - accuracy: 0.9763 - val_loss: 0.7221 - val_accuracy: 0.8421\n","Epoch 18/30\n","72/72 [==============================] - 102s 1s/step - loss: 0.0814 - accuracy: 0.9798 - val_loss: 0.7165 - val_accuracy: 0.8421\n","Epoch 19/30\n","72/72 [==============================] - 99s 1s/step - loss: 0.0753 - accuracy: 0.9794 - val_loss: 0.7112 - val_accuracy: 0.8526\n","Epoch 20/30\n","72/72 [==============================] - 98s 1s/step - loss: 0.0677 - accuracy: 0.9833 - val_loss: 0.7207 - val_accuracy: 0.8474\n","Epoch 21/30\n","72/72 [==============================] - 102s 1s/step - loss: 0.0631 - accuracy: 0.9859 - val_loss: 0.7083 - val_accuracy: 0.8579\n","Epoch 22/30\n","72/72 [==============================] - 98s 1s/step - loss: 0.0574 - accuracy: 0.9877 - val_loss: 0.7085 - val_accuracy: 0.8579\n","Epoch 23/30\n","72/72 [==============================] - 101s 1s/step - loss: 0.0538 - accuracy: 0.9895 - val_loss: 0.7151 - val_accuracy: 0.8579\n","Epoch 24/30\n","72/72 [==============================] - 107s 1s/step - loss: 0.0495 - accuracy: 0.9890 - val_loss: 0.7031 - val_accuracy: 0.8579\n","Epoch 25/30\n","72/72 [==============================] - 136s 2s/step - loss: 0.0466 - accuracy: 0.9917 - val_loss: 0.7026 - val_accuracy: 0.8614\n","Epoch 26/30\n","72/72 [==============================] - 145s 2s/step - loss: 0.0457 - accuracy: 0.9912 - val_loss: 0.7014 - val_accuracy: 0.8579\n","Epoch 27/30\n","72/72 [==============================] - 161s 2s/step - loss: 0.0393 - accuracy: 0.9930 - val_loss: 0.7068 - val_accuracy: 0.8614\n","Epoch 28/30\n","72/72 [==============================] - 167s 2s/step - loss: 0.0375 - accuracy: 0.9939 - val_loss: 0.7010 - val_accuracy: 0.8632\n","Epoch 29/30\n","72/72 [==============================] - 145s 2s/step - loss: 0.0336 - accuracy: 0.9943 - val_loss: 0.6986 - val_accuracy: 0.8632\n","Epoch 30/30\n","72/72 [==============================] - 162s 2s/step - loss: 0.0321 - accuracy: 0.9960 - val_loss: 0.7020 - val_accuracy: 0.8649\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x2cfd18760>"]},"execution_count":120,"metadata":{},"output_type":"execute_result"}],"source":["# Entrenar el modelo con los datos de entrenamiento\n","model.fit(X_train_tf, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":101,"metadata":{"id":"5U_JFq4Icn41"},"outputs":[],"source":["# Guardar el modelo entrenado\n","model.save('ModelosFinales/modeloGuanacoVGG16_v2.h5')"]},{"cell_type":"code","execution_count":121,"metadata":{"id":"9nvfONpccn42","outputId":"0cd326f7-cce5-48cd-dfd2-9cb58b58bf84"},"outputs":[{"name":"stdout","output_type":"stream","text":["23/23 [==============================] - 32s 1s/step\n"]}],"source":["y_proba = model.predict(X_test_tf)\n","y_pred = (y_proba >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":122,"metadata":{"id":"_Q68mlQScn42","outputId":"c79bc363-baf7-489c-f85b-d4e352b77d73"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8735955056179775\n","Recall: 0.8970917225950783\n","Precision: 0.9011235955056179\n","Specificity: 0.8339622641509434\n"]}],"source":["# Calculamos Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Calculamos Recall\n","recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Recall: {recall}\")\n","\n","# Calculamos Precision\n","precision = precision_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Precision: {precision}\")\n","\n","# Calculamos Specificity\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","specificity = tn / (tn + fp)\n","print(f\"Specificity: {specificity}\")\n","\n","# Accuracy: 0.8932584269662921\n","# Recall: 0.9105145413870246\n","# Precision: 0.9187358916478555\n","# Specificity: 0.8641509433962264"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"XK62nQ-7cn42","outputId":"f5a9f6a9-0818-4e07-983a-c9301aa1c202"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision (AP): 0.8610577537065705\n"]}],"source":["# Calcular average precision\n","ap = average_precision_score(y_test, y_proba)\n","\n","print(\"Average Precision (AP):\", ap)\n","\n","# Average Precision (AP): 0.9239772259039202"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qIx71vHjcn43","outputId":"7309b0f9-19ab-4020-fdcb-9603a5717f9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","       False       0.39      0.96      0.56       138\n","        True       0.95      0.31      0.46       299\n","\n","    accuracy                           0.51       437\n","   macro avg       0.67      0.64      0.51       437\n","weighted avg       0.77      0.51      0.49       437\n","\n"]}],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cm-lxoYicn43","outputId":"36c73d65-088d-4406-a7d4-9d8fd51708fc"},"outputs":[{"data":{"text/plain":["0.7780320366132724"]},"execution_count":352,"metadata":{},"output_type":"execute_result"}],"source":["(y_pred == 0).sum() / len(y_pred)"]},{"cell_type":"markdown","metadata":{"id":"5TkOE7uAcn43"},"source":["# Entrenamiento Categoria Especie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jcF5Mefcn43"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('ArchivosUtiles/trainingCategoria.pkl')\n","test = pd.read_pickle('ArchivosUtiles/testingCategoria.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B8vlLXGwcn49"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Categoria']\n","X_test = test['Imagen']\n","y_test = test['Categoria']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vHN3i8Dkcn49"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{},"source":["# Entrenamiento Aislado"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('ArchivosUtiles/trainingAislado.pkl')\n","test = pd.read_pickle('ArchivosUtiles/testingAislado.pkl')"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Aislado']\n","X_test = test['Imagen']\n","y_test = test['Aislado']"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{},"source":["## Balanceo"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"data":{"text/plain":["Aislado\n","0    829\n","1    829\n","Name: count, dtype: int64"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["y_train.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["## Descarga del modelo VGG16 pre-entrenado:\n","Descarga el modelo VGG16 pre-entrenado con pesos de ImageNet. Puedes hacerlo utilizando TensorFlow o Keras."]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["input_shape = (150, 150, 3)"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[],"source":["# Carga el modelo VGG16 preentrenado con pesos de ImageNet (no incluye las capas densas superiores)\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Entrenamiento del modelo:\n","\n","Añade capas personalizadas en la parte superior del modelo VGG16 y entrena el modelo en tus datos utilizando el generador de datos. Asegúrate de congelar las capas base de VGG16 para que no se actualicen durante el entrenamiento."]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["# Agregar capas personalizadas en la parte superior del modelo base\n","x = Flatten()(base_model.output)  # Flatten output to 1 dimension\n","\n","# # Agregar más capas densas\n","# x = Dense(1024, activation='relu')(x)  # Añade una capa con Relu activation\n","# x = Dropout(0.2)(x)  # Añade un dropout rate de 0.2\n","\n","# # Agregar más capas densas\n","# x = Dense(512, activation='relu')(x)\n","# x = Dropout(0.3)(x)\n","\n","# # Agregar más capas densas\n","# x = Dense(256, activation='relu')(x)\n","# x = Dropout(0.2)(x)\n","\n","# # Agregar más capas densas\n","# x = Dense(128, activation='relu')(x)\n","# x = Dropout(0.2)(x)\n","\n","# Capa de salida\n","predictions = Dense(1, activation='sigmoid')(x)"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":["# Crear el modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[],"source":["# Congelar las capas del modelo base para el transfer learning\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[],"source":["# Define the EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=5,           # Number of epochs with no improvement after which training will be stopped\n","    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",")"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[],"source":["# Compilar el modelo\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","42/42 [==============================] - 99s 2s/step - loss: 2.8949 - accuracy: 0.6222 - val_loss: 2.4954 - val_accuracy: 0.6687\n","Epoch 2/30\n","42/42 [==============================] - 96s 2s/step - loss: 1.1120 - accuracy: 0.7624 - val_loss: 2.3405 - val_accuracy: 0.6837\n","Epoch 3/30\n","42/42 [==============================] - 116s 3s/step - loss: 0.6411 - accuracy: 0.8273 - val_loss: 2.5806 - val_accuracy: 0.6898\n","Epoch 4/30\n","42/42 [==============================] - 100s 2s/step - loss: 0.3683 - accuracy: 0.8869 - val_loss: 2.2491 - val_accuracy: 0.6747\n","Epoch 5/30\n","42/42 [==============================] - 217s 5s/step - loss: 0.2862 - accuracy: 0.8944 - val_loss: 2.4043 - val_accuracy: 0.6717\n","Epoch 6/30\n","42/42 [==============================] - 264s 6s/step - loss: 0.2074 - accuracy: 0.9216 - val_loss: 2.1060 - val_accuracy: 0.6777\n","Epoch 7/30\n","42/42 [==============================] - 219s 5s/step - loss: 0.2127 - accuracy: 0.9238 - val_loss: 2.3147 - val_accuracy: 0.7018\n","Epoch 8/30\n","42/42 [==============================] - 230s 5s/step - loss: 0.2426 - accuracy: 0.9216 - val_loss: 2.5522 - val_accuracy: 0.6837\n","Epoch 9/30\n","42/42 [==============================] - 169s 4s/step - loss: 0.1239 - accuracy: 0.9578 - val_loss: 2.5271 - val_accuracy: 0.6837\n","Epoch 10/30\n","42/42 [==============================] - 105s 2s/step - loss: 0.1114 - accuracy: 0.9691 - val_loss: 2.5805 - val_accuracy: 0.6898\n","Epoch 11/30\n","42/42 [==============================] - 89s 2s/step - loss: 0.0926 - accuracy: 0.9691 - val_loss: 2.6661 - val_accuracy: 0.6928\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fc919e13fa0>"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["# Entrenar el modelo con los datos de entrenamiento\n","model.fit(X_train_tf, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[],"source":["# Guardar el modelo entrenado\n","model.save('ModelosFinales/modeloAisladoVGG16.h5')"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 24s 2s/step\n"]}],"source":["y_proba = model.predict(X_test_tf)\n","y_pred = (y_proba >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.6265060240963856\n","Recall: 0.6811594202898551\n","Precision: 0.6130434782608696\n","Specificity: 0.5721153846153846\n"]}],"source":["# Calculamos Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Calculamos Recall\n","recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Recall: {recall}\")\n","\n","# Calculamos Precision\n","precision = precision_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Precision: {precision}\")\n","\n","# Calculamos Specificity\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","specificity = tn / (tn + fp)\n","print(f\"Specificity: {specificity}\")\n","\n","# Accuracy: 0.5927710843373494\n","# Recall: 0.5942028985507246\n","# Precision: 0.5913461538461539\n","# Specificity: 0.5913461538461539"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision (AP): 0.591230552516077\n"]}],"source":["# Calcular average precision\n","ap = average_precision_score(y_test, y_proba)\n","\n","print(\"Average Precision (AP):\", ap)\n","\n","# Average Precision (AP): 0.9239772259039202"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","       False       0.39      0.96      0.56       138\n","        True       0.95      0.31      0.46       299\n","\n","    accuracy                           0.51       437\n","   macro avg       0.67      0.64      0.51       437\n","weighted avg       0.77      0.51      0.49       437\n","\n"]}],"source":["print(classification_report(y_test, y_pred))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
