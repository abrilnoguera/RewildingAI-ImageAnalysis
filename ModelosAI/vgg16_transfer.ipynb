{"cells":[{"cell_type":"markdown","metadata":{"id":"9QgWy64mefKs"},"source":["Para replicar el referenciamiento de ImageNet en tu propio dataset de imágenes almacenado en Amazon S3 y ejecutar la transferencia de aprendizaje con VGG16, debes seguir varios pasos. Aquí tienes una guía general sobre cómo hacerlo:\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"--MGqE0-ejHh"},"outputs":[{"name":"stdout","output_type":"stream","text":["Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n","Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"]},{"name":"stderr","output_type":"stream","text":["2023-11-11 16:54:11.026158: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["# Librerías estándar\n","import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from io import BytesIO\n","\n","# TensorFlow y Keras\n","import tensorflow as tf\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import (Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D, MaxPooling2D, Reshape)\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n","\n","# Otras librerías\n","import os\n","import boto3\n","from PIL import Image\n","from sklearn.metrics import (accuracy_score, auc, average_precision_score, classification_report,\n","                             confusion_matrix, precision_score, recall_score)\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"SilxVuzGcn4e"},"source":["# Entrenamiento Animal y No Animal"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"k2NXUxbkcn4e"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('ArchivosUtiles/trainingAnimal.pkl')\n","test = pd.read_pickle('ArchivosUtiles/testingAnimal.pkl')"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"xaXOJxH9cn4e"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Animal']\n","X_test = test['Imagen']\n","y_test = test['Animal']"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"rVp6rm74cn4e"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{"id":"XMnvI64Nf_sQ"},"source":["## Descarga del modelo VGG16 pre-entrenado:\n","Descarga el modelo VGG16 pre-entrenado con pesos de ImageNet. Puedes hacerlo utilizando TensorFlow o Keras."]},{"cell_type":"code","execution_count":71,"metadata":{"id":"XJTxGKtGgdz1"},"outputs":[],"source":["input_shape = (150, 150, 3)"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"BIgdNTQTgfgs"},"outputs":[],"source":["# Carga el modelo VGG16 preentrenado con pesos de ImageNet (no incluye las capas densas superiores)\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"]},{"cell_type":"markdown","metadata":{"id":"V6GuJ5YOgNHW"},"source":["## Generador de datos:\n","\n","Utiliza un generador de datos de Keras para cargar y preprocesar tus imágenes desde S3. Debes proporcionar la ruta a tus imágenes en S3 y etiquetas correspondientes. Aquí un ejemplo de cómo configurar un generador de datos:"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"7Sk25YR_kb8U"},"outputs":[],"source":["# Número de clases en tu conjunto de datos\n","num_classes = len(y_train.unique())"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"IL-a9_xbkvZn"},"outputs":[],"source":["# Tamaño del lote (batch size) que deseas utilizar durante el entrenamiento\n","batch_size = 32"]},{"cell_type":"markdown","metadata":{"id":"LpvkgxD3cn4g"},"source":["## Entrenamiento del modelo:\n","\n","Añade capas personalizadas en la parte superior del modelo VGG16 y entrena el modelo en tus datos utilizando el generador de datos. Asegúrate de congelar las capas base de VGG16 para que no se actualicen durante el entrenamiento."]},{"cell_type":"code","execution_count":75,"metadata":{"id":"CD74A8wCcn4g"},"outputs":[],"source":["# Agregar capas personalizadas en la parte superior del modelo base\n","x = Flatten()(base_model.output) #Flatten output to 1 dimension\n","x = Dense(1024,activation='relu')(x) #Añade una layer con Relu activation\n","x = Dropout(0.2)(x) #Añade un dropout rate de 0.2\n","predictions = Dense(1, activation = 'sigmoid')(x)"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"BrlcuY_mcn4g"},"outputs":[],"source":["# Crear el modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"CcZSIgh9cn4h"},"outputs":[],"source":["# Congelar las capas del modelo base para el transfer learning\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"bHbMQBbpcn4h"},"outputs":[],"source":["# Compilar el modelo\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"5c-f-G3Hcn4h"},"outputs":[],"source":["# Define the EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=5,           # Number of epochs with no improvement after which training will be stopped\n","    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPR7VFsNcn4i"},"outputs":[],"source":["# Entrena el modelo con los datos de entrenamiento\n","model.fit(X_train_tf, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w2NsNXwtcn4i"},"outputs":[],"source":["# Guardar el modelo entrenado\n","model.save('ModelosFinales/modeloAnimalVGG16.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8L6vW1wWcn4j","outputId":"ed9d69a1-af32-45c1-9720-a766db10b1ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["38/38 [==============================] - 79s 2s/step\n"]}],"source":["y_proba = model.predict(X_test_tf)\n","y_pred = (y_proba >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z30PY8nLcn4j","outputId":"a10da620-0e63-42f5-f8a6-d10b2a3bc6f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9696714406065712\n","Recall: 0.9854838709677419\n","Specificity: 0.9523809523809523\n"]}],"source":["# Calculamos Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Calculamos Recall\n","recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Recall: {recall}\")\n","\n","# Calculamos Specificity\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","specificity = tn / (tn + fp)\n","print(f\"Specificity: {specificity}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RI46LS2Acn4k","outputId":"8b2409c4-fd1d-42a1-8085-811bd8841917"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision (AP): 0.9867896712891505\n"]}],"source":["# Calcular average precision\n","ap = average_precision_score(y_test, y_proba)\n","\n","print(\"Average Precision (AP):\", ap)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Za6vMqCCcn4k","outputId":"ff12b0d8-c471-48cf-f5b0-d76fe5b7d5c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.98      0.95      0.97       567\n","           1       0.96      0.99      0.97       620\n","\n","    accuracy                           0.97      1187\n","   macro avg       0.97      0.97      0.97      1187\n","weighted avg       0.97      0.97      0.97      1187\n","\n"]}],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"J0IgauQCcn4l"},"source":["# Entrenamiento Guanaco y No Guanaco"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"8N0g-ZY5cn4l"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('ArchivosUtiles/trainingGuanaco.pkl')\n","test = pd.read_pickle('ArchivosUtiles/testingGuanaco.pkl')"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"MLkzZqP4cn4l"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Guanaco']\n","X_test = test['Imagen']\n","y_test = test['Guanaco']"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"15bqeJA_cn4v"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{"id":"uJPIz6-4cn4w"},"source":["## Balanceo"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"WpEMtRrbcn4w","outputId":"baf9c258-3298-4497-85c5-00f9adbabb92"},"outputs":[{"data":{"text/plain":["Guanaco\n","True     1187\n","False     539\n","Name: count, dtype: int64"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["y_train.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"5oi8oQWPcn4w"},"source":["La base esta desbalanceada ya que existen muchos mas guanacos que otros animales. Para resolver esto se somete al resto de los animales a tecnicas de *Data Augmentation*"]},{"cell_type":"markdown","metadata":{"id":"RZZYJ2DRcn4x"},"source":["Data Augmentation: make training set larger by applying transformations. More information to learn from.\n","- Brightness and Contrast adjustments\n","- Rotations\n","- Gaussian noise\n","- Mirroring"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"XG4EE2FMcn4x"},"outputs":[],"source":["def data_augmentation(image_tensor):\n","\n","    # Convierte el tensor de imagen a una imagen TensorFlow\n","    image = tf.convert_to_tensor(image_tensor, dtype=tf.float32)\n","\n","    # Brightness and Contrast adjustments\n","    if np.random.rand() < 0.8:\n","        image = tf.image.adjust_brightness(image, delta=0.2)  # Cambiar el brillo\n","        image = tf.image.adjust_contrast(image, contrast_factor=1.2)  # Cambiar el contraste\n","\n","    # Rotations\n","    if np.random.rand() < 0.7:\n","        degrees = np.random.uniform(-10, 10)  # Rotación aleatoria entre -10 y 10 grados\n","        degrees = int(round(degrees))  # Redondea los grados a un entero\n","        image = tf.image.rot90(image, k=degrees // 90)  # Rotar la imagen\n","\n","    # Gaussian noise\n","    if np.random.rand() < 0.2:\n","        noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.1)\n","        image = image + noise\n","\n","    # Mirroring (flip horizontal)\n","    if np.random.rand() < 0.5:\n","        image = tf.image.flip_left_right(image)\n","\n","    # Convierte la imagen aumentada de nuevo a un tensor\n","    augmented_image_tensor = tf.convert_to_tensor(image.numpy(), dtype=tf.float32)\n","\n","    return augmented_image_tensor"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"8HvJo8COcn4x"},"outputs":[],"source":["# Crea una nueva lista para almacenar los tensores de imágenes aumentados\n","imagen_tensor_aumentada = []\n","\n","# Itera a través de las filas del DataFrame y aplica la función de aumento de datos\n","for index, row in train.iterrows():\n","    if np.random.rand() < 0.38:\n","        imagen_tensor = row['Imagen']\n","        imagen_aumentada = data_augmentation(imagen_tensor)\n","        imagen_tensor_aumentada.append(imagen_aumentada)"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"SdMZMqFYcn4y"},"outputs":[],"source":["train_augmentation = pd.DataFrame(columns=['Imagen', 'Guanaco'])\n","train_augmentation['Imagen'] = imagen_tensor_aumentada\n","train_augmentation['Guanaco'] = False"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"an0ZqnQlcn4y"},"outputs":[],"source":["train_augmentation= pd.concat([train, train_augmentation], ignore_index=True)"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"WJdtoeLjcn4y","outputId":"61ad4588-7888-4209-cf5d-2e95e7470c6a"},"outputs":[{"data":{"text/plain":["Guanaco\n","False    1203\n","True     1187\n","Name: count, dtype: int64"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["train_augmentation['Guanaco'].value_counts()"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"ABm-6-S9cn4y"},"outputs":[],"source":["X_train = train_augmentation['Imagen']\n","y_train = train_augmentation['Guanaco']"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"fLCtpmGFcn4z"},"outputs":[],"source":["X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))"]},{"cell_type":"markdown","metadata":{"id":"Hf6BXZehcn4z"},"source":["## Descarga del modelo VGG16 pre-entrenado:\n","Descarga el modelo VGG16 pre-entrenado con pesos de ImageNet. Puedes hacerlo utilizando TensorFlow o Keras."]},{"cell_type":"code","execution_count":103,"metadata":{"id":"tbJiADgVcn4z"},"outputs":[],"source":["input_shape = (150, 150, 3)"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"FCNve5CScn4z"},"outputs":[],"source":["# Carga el modelo VGG16 preentrenado con pesos de ImageNet (no incluye las capas densas superiores)\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"]},{"cell_type":"markdown","metadata":{"id":"dquYhTIllN48"},"source":["## Entrenamiento del modelo:\n","\n","Añade capas personalizadas en la parte superior del modelo VGG16 y entrena el modelo en tus datos utilizando el generador de datos. Asegúrate de congelar las capas base de VGG16 para que no se actualicen durante el entrenamiento."]},{"cell_type":"code","execution_count":105,"metadata":{"id":"wiUDCsHmcn40"},"outputs":[],"source":["# Agregar capas personalizadas en la parte superior del modelo base\n","x = Flatten()(base_model.output)  # Flatten output to 1 dimension\n","\n","# Agregar más capas densas\n","x = Dense(1024, activation='relu')(x)  # Añade una capa con Relu activation\n","x = Dropout(0.2)(x)  # Añade un dropout rate de 0.2\n","\n","# Agregar más capas densas\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.3)(x)\n","\n","# Agregar más capas densas\n","x = Dense(256, activation='relu')(x)\n","x = Dropout(0.2)(x)\n","\n","# Agregar más capas densas\n","x = Dense(128, activation='relu')(x)\n","x = Dropout(0.2)(x)\n","\n","# Capa de salida\n","predictions = Dense(1, activation='sigmoid')(x)"]},{"cell_type":"code","execution_count":106,"metadata":{"id":"MXs_FglPcn40"},"outputs":[],"source":["# Crear el modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":107,"metadata":{"id":"C54GZI5Scn40"},"outputs":[],"source":["# Congelar las capas del modelo base para el transfer learning\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":108,"metadata":{"id":"o-M7fJNtcn40"},"outputs":[],"source":["# Define the EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=5,           # Number of epochs with no improvement after which training will be stopped\n","    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",")"]},{"cell_type":"code","execution_count":109,"metadata":{"id":"6A_yt6kBcn41"},"outputs":[],"source":["# Compilar el modelo\n","model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":110,"metadata":{"id":"-6mxEqjTcn41","outputId":"f623eb48-2298-4b17-a9db-0fc41c56527b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","60/60 [==============================] - 218s 4s/step - loss: 19.5518 - accuracy: 0.6323 - val_loss: 1.6164 - val_accuracy: 0.5607\n","Epoch 2/30\n","60/60 [==============================] - 217s 4s/step - loss: 1.0882 - accuracy: 0.6804 - val_loss: 1.9825 - val_accuracy: 0.2929\n","Epoch 3/30\n","60/60 [==============================] - 217s 4s/step - loss: 0.8517 - accuracy: 0.6878 - val_loss: 0.7719 - val_accuracy: 0.1444\n","Epoch 4/30\n","60/60 [==============================] - 214s 4s/step - loss: 0.6959 - accuracy: 0.6538 - val_loss: 0.8645 - val_accuracy: 0.0858\n","Epoch 5/30\n","60/60 [==============================] - 219s 4s/step - loss: 0.7015 - accuracy: 0.6742 - val_loss: 0.9426 - val_accuracy: 0.1025\n","Epoch 6/30\n","60/60 [==============================] - 203s 3s/step - loss: 0.6349 - accuracy: 0.6904 - val_loss: 0.6851 - val_accuracy: 0.3703\n","Epoch 7/30\n","60/60 [==============================] - 132s 2s/step - loss: 0.6031 - accuracy: 0.6930 - val_loss: 0.8089 - val_accuracy: 0.2678\n","Epoch 8/30\n","60/60 [==============================] - 126s 2s/step - loss: 0.8361 - accuracy: 0.6747 - val_loss: 0.8894 - val_accuracy: 0.1862\n","Epoch 9/30\n","60/60 [==============================] - 124s 2s/step - loss: 0.6912 - accuracy: 0.6579 - val_loss: 0.6928 - val_accuracy: 0.3347\n","Epoch 10/30\n","60/60 [==============================] - 126s 2s/step - loss: 0.7346 - accuracy: 0.6606 - val_loss: 1.0445 - val_accuracy: 0.0000e+00\n","Epoch 11/30\n","60/60 [==============================] - 127s 2s/step - loss: 0.6629 - accuracy: 0.6224 - val_loss: 0.9873 - val_accuracy: 0.0000e+00\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f936150e850>"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["# Entrenar el modelo con los datos de entrenamiento\n","model.fit(X_train_tf, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5U_JFq4Icn41"},"outputs":[],"source":["# Guardar el modelo entrenado\n","model.save('ModelosFinales/modeloGuanacoVGG16.h5')"]},{"cell_type":"code","execution_count":111,"metadata":{"id":"9nvfONpccn42","outputId":"0cd326f7-cce5-48cd-dfd2-9cb58b58bf84"},"outputs":[{"name":"stdout","output_type":"stream","text":["14/14 [==============================] - 26s 2s/step\n"]}],"source":["y_proba = model.predict(X_test_tf)\n","y_pred = (y_proba >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"_Q68mlQScn42","outputId":"c79bc363-baf7-489c-f85b-d4e352b77d73"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.7413394919168591\n","Recall: 0.7181208053691275\n","Precision: 0.8842975206611571\n","Specificity: 0.7925925925925926\n"]}],"source":["# Calculamos Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Calculamos Recall\n","recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Recall: {recall}\")\n","\n","# Calculamos Precision\n","precision = precision_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Precision: {precision}\")\n","\n","# Calculamos Specificity\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","specificity = tn / (tn + fp)\n","print(f\"Specificity: {specificity}\")\n","\n","# Accuracy: 0.8283752860411899\n","# Recall: 0.903010033444816\n","# Precision: 0.8544303797468354\n","# Specificity: 0.6666666666666666"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"XK62nQ-7cn42","outputId":"f5a9f6a9-0818-4e07-983a-c9301aa1c202"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision (AP): 0.8610577537065705\n"]}],"source":["# Calcular average precision\n","ap = average_precision_score(y_test, y_proba)\n","\n","print(\"Average Precision (AP):\", ap)\n","\n","# Average Precision (AP): 0.9239772259039202"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qIx71vHjcn43","outputId":"7309b0f9-19ab-4020-fdcb-9603a5717f9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","       False       0.39      0.96      0.56       138\n","        True       0.95      0.31      0.46       299\n","\n","    accuracy                           0.51       437\n","   macro avg       0.67      0.64      0.51       437\n","weighted avg       0.77      0.51      0.49       437\n","\n"]}],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cm-lxoYicn43","outputId":"36c73d65-088d-4406-a7d4-9d8fd51708fc"},"outputs":[{"data":{"text/plain":["0.7780320366132724"]},"execution_count":352,"metadata":{},"output_type":"execute_result"}],"source":["(y_pred == 0).sum() / len(y_pred)"]},{"cell_type":"markdown","metadata":{"id":"5TkOE7uAcn43"},"source":["# Entrenamiento Categoria Especie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jcF5Mefcn43"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('ArchivosUtiles/trainingCategoria.pkl')\n","test = pd.read_pickle('ArchivosUtiles/testingCategoria.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B8vlLXGwcn49"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Categoria']\n","X_test = test['Imagen']\n","y_test = test['Categoria']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vHN3i8Dkcn49"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
