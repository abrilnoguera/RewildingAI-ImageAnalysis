{"cells":[{"cell_type":"markdown","metadata":{"id":"9QgWy64mefKs"},"source":["Para replicar el referenciamiento de ImageNet en tu propio dataset de imágenes almacenado en Amazon S3 y ejecutar la transferencia de aprendizaje con ResNet, debes seguir varios pasos. Aquí tienes una guía general sobre cómo hacerlo:\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1037,"status":"ok","timestamp":1696793001831,"user":{"displayName":"LUCAS ARBUES","userId":"10189924890821610700"},"user_tz":180},"id":"--MGqE0-ejHh"},"outputs":[],"source":["# Librerías estándar\n","import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from io import BytesIO\n","\n","# TensorFlow y Keras\n","import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import (Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D, MaxPooling2D, Reshape)\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n","\n","# Otras librerías\n","import os\n","import boto3\n","from PIL import Image\n","from sklearn.metrics import (accuracy_score, auc, average_precision_score, classification_report, \n","                             confusion_matrix, precision_score, recall_score)\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"SilxVuzGcn4e"},"source":["# Entrenamiento Animal y No Animal"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"k2NXUxbkcn4e"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('ArchivosUtiles/trainingAnimal.pkl')\n","test = pd.read_pickle('ArchivosUtiles/testingAnimal.pkl')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xaXOJxH9cn4e"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Animal']\n","X_test = test['Imagen']\n","y_test = test['Animal']"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"rVp6rm74cn4e"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{"id":"XMnvI64Nf_sQ"},"source":["## Descarga del modelo ResNet50 pre-entrenado:\n","Descarga el modelo ResNet50 pre-entrenado con pesos de ImageNet. Puedes hacerlo utilizando TensorFlow o Keras."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"XJTxGKtGgdz1"},"outputs":[],"source":["input_shape = (150, 150, 3)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"BIgdNTQTgfgs"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 12s 0us/step\n"]}],"source":["# Carga el modelo ResNet50 preentrenado con pesos de ImageNet \n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)"]},{"cell_type":"markdown","metadata":{"id":"V6GuJ5YOgNHW"},"source":["## Generador de datos:\n","\n","Utiliza un generador de datos de Keras para cargar y preprocesar tus imágenes desde S3. Debes proporcionar la ruta a tus imágenes en S3 y etiquetas correspondientes. Aquí un ejemplo de cómo configurar un generador de datos:"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"7Sk25YR_kb8U"},"outputs":[],"source":["# Número de clases en tu conjunto de datos\n","num_classes = len(y_train.unique())"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"IL-a9_xbkvZn"},"outputs":[],"source":["# Tamaño del lote (batch size) que deseas utilizar durante el entrenamiento\n","batch_size = 32"]},{"cell_type":"markdown","metadata":{"id":"LpvkgxD3cn4g"},"source":["## Entrenamiento del modelo:\n","\n","Añade capas personalizadas en la parte superior del modelo VGG16 y entrena el modelo en tus datos utilizando el generador de datos. Asegúrate de congelar las capas base de ResNet para que no se actualicen durante el entrenamiento."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"CD74A8wCcn4g"},"outputs":[],"source":["# Agregar capas personalizadas en la parte superior del modelo base\n","x = Flatten()(base_model.output) #Flatten output to 1 dimension\n","x = Dense(1024,activation='relu')(x) #Añade una layer con Relu activation\n","x = Dropout(0.2)(x) #Añade un dropout rate de 0.2\n","predictions = Dense(1, activation = 'sigmoid')(x)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"BrlcuY_mcn4g"},"outputs":[],"source":["# Crear el modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"CcZSIgh9cn4h"},"outputs":[],"source":["# Congelar las capas del modelo base para el transfer learning\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"bHbMQBbpcn4h"},"outputs":[],"source":["# Compilar el modelo\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"5c-f-G3Hcn4h"},"outputs":[],"source":["# Define the EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=5,           # Number of epochs with no improvement after which training will be stopped\n","    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"mPR7VFsNcn4i","outputId":"473b88a6-df57-4b6f-c5d4-35abe18326a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","119/119 [==============================] - 152s 1s/step - loss: 2.1522 - accuracy: 0.9505 - val_loss: 2.4049 - val_accuracy: 0.9663\n","Epoch 2/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.7180 - accuracy: 0.9797 - val_loss: 2.4509 - val_accuracy: 0.9663\n","Epoch 3/30\n","119/119 [==============================] - 147s 1s/step - loss: 0.5401 - accuracy: 0.9784 - val_loss: 2.0228 - val_accuracy: 0.9611\n","Epoch 4/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.2824 - accuracy: 0.9860 - val_loss: 2.1384 - val_accuracy: 0.9611\n","Epoch 5/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.2759 - accuracy: 0.9863 - val_loss: 1.3570 - val_accuracy: 0.9463\n","Epoch 6/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.1690 - accuracy: 0.9881 - val_loss: 1.3414 - val_accuracy: 0.9611\n","Epoch 7/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.1566 - accuracy: 0.9897 - val_loss: 1.0647 - val_accuracy: 0.9653\n","Epoch 8/30\n","119/119 [==============================] - 142s 1s/step - loss: 0.1061 - accuracy: 0.9910 - val_loss: 0.7029 - val_accuracy: 0.9579\n","Epoch 9/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.0682 - accuracy: 0.9926 - val_loss: 0.5232 - val_accuracy: 0.9526\n","Epoch 10/30\n","119/119 [==============================] - 147s 1s/step - loss: 0.0373 - accuracy: 0.9937 - val_loss: 0.5017 - val_accuracy: 0.9505\n","Epoch 11/30\n","119/119 [==============================] - 148s 1s/step - loss: 0.0347 - accuracy: 0.9932 - val_loss: 0.4686 - val_accuracy: 0.9537\n","Epoch 12/30\n","119/119 [==============================] - 146s 1s/step - loss: 0.0804 - accuracy: 0.9892 - val_loss: 0.8011 - val_accuracy: 0.9611\n","Epoch 13/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.0640 - accuracy: 0.9908 - val_loss: 0.5908 - val_accuracy: 0.9558\n","Epoch 14/30\n","119/119 [==============================] - 152s 1s/step - loss: 0.0633 - accuracy: 0.9926 - val_loss: 0.6939 - val_accuracy: 0.9663\n","Epoch 15/30\n","119/119 [==============================] - 157s 1s/step - loss: 0.0593 - accuracy: 0.9889 - val_loss: 0.6389 - val_accuracy: 0.9589\n","Epoch 16/30\n","119/119 [==============================] - 141s 1s/step - loss: 0.0561 - accuracy: 0.9913 - val_loss: 0.4477 - val_accuracy: 0.9611\n","Epoch 17/30\n","119/119 [==============================] - 145s 1s/step - loss: 0.0450 - accuracy: 0.9910 - val_loss: 0.5219 - val_accuracy: 0.9568\n","Epoch 18/30\n","119/119 [==============================] - 211s 2s/step - loss: 0.0475 - accuracy: 0.9926 - val_loss: 0.7946 - val_accuracy: 0.9663\n","Epoch 19/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.1119 - accuracy: 0.9866 - val_loss: 1.1067 - val_accuracy: 0.9632\n","Epoch 20/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.1473 - accuracy: 0.9881 - val_loss: 0.8134 - val_accuracy: 0.9621\n","Epoch 21/30\n","119/119 [==============================] - 159s 1s/step - loss: 0.1366 - accuracy: 0.9884 - val_loss: 1.0215 - val_accuracy: 0.9600\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fdfb455bfa0>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Entrena el modelo con los datos de entrenamiento\n","model.fit(X_train_tf, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"w2NsNXwtcn4i"},"outputs":[],"source":["# Guardar el modelo entrenado\n","model.save('ModelosFinales/modeloAnimalRN50.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8L6vW1wWcn4j","outputId":"ed9d69a1-af32-45c1-9720-a766db10b1ce"},"outputs":[],"source":["y_proba = model.predict(X_test_tf)\n","y_pred = (y_proba >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z30PY8nLcn4j","outputId":"a10da620-0e63-42f5-f8a6-d10b2a3bc6f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9713563605728728\n","Recall: 0.9838709677419355\n","Specificity: 0.9576719576719577\n"]}],"source":["# Calculamos Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Calculamos Recall\n","recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Recall: {recall}\")\n","\n","# Calculamos Specificity\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","specificity = tn / (tn + fp)\n","print(f\"Specificity: {specificity}\")"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"RI46LS2Acn4k","outputId":"8b2409c4-fd1d-42a1-8085-811bd8841917"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision (AP): 0.9829587558124374\n"]}],"source":["# Calcular average precision\n","ap = average_precision_score(y_test, y_proba)\n","\n","print(\"Average Precision (AP):\", ap)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Za6vMqCCcn4k","outputId":"ff12b0d8-c471-48cf-f5b0-d76fe5b7d5c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.98      0.96      0.97       567\n","           1       0.96      0.98      0.97       620\n","\n","    accuracy                           0.97      1187\n","   macro avg       0.97      0.97      0.97      1187\n","weighted avg       0.97      0.97      0.97      1187\n","\n"]}],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"J0IgauQCcn4l"},"source":["# Entrenamiento Guanaco y No Guanaco"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"8N0g-ZY5cn4l"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('ArchivosUtiles/trainingGuanaco.pkl')\n","test = pd.read_pickle('ArchivosUtiles/testingGuanaco.pkl')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"MLkzZqP4cn4l"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Guanaco'].astype('float32')\n","X_test = test['Imagen']\n","y_test = test['Guanaco'].astype('float32')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"15bqeJA_cn4v"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{"id":"uJPIz6-4cn4w"},"source":["## Balanceo"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"WpEMtRrbcn4w","outputId":"baf9c258-3298-4497-85c5-00f9adbabb92"},"outputs":[{"data":{"text/plain":["Guanaco\n","True     1180\n","False     530\n","Name: count, dtype: int64"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["y_train.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"5oi8oQWPcn4w"},"source":["La base esta desbalanceada ya que existen muchos mas guanacos que otros animales. Para resolver esto se somete al resto de los animales a tecnicas de *Data Augmentation*"]},{"cell_type":"markdown","metadata":{"id":"RZZYJ2DRcn4x"},"source":["Data Augmentation: make training set larger by applying transformations. More information to learn from.\n","- Brightness and Contrast adjustments\n","- Rotations\n","- Gaussian noise\n","- Mirroring"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"XG4EE2FMcn4x"},"outputs":[],"source":["def data_augmentation(image_tensor):\n","\n","    # Convierte el tensor de imagen a una imagen TensorFlow\n","    image = tf.convert_to_tensor(image_tensor, dtype=tf.float32)\n","\n","    # Brightness and Contrast adjustments\n","    if np.random.rand() < 0.8:\n","        image = tf.image.adjust_brightness(image, delta=0.2)  # Cambiar el brillo\n","        image = tf.image.adjust_contrast(image, contrast_factor=1.2)  # Cambiar el contraste\n","\n","    # Rotations\n","    if np.random.rand() < 0.7:\n","        degrees = np.random.uniform(-10, 10)  # Rotación aleatoria entre -10 y 10 grados\n","        degrees = int(round(degrees))  # Redondea los grados a un entero\n","        image = tf.image.rot90(image, k=degrees // 90)  # Rotar la imagen\n","\n","    # Gaussian noise\n","    if np.random.rand() < 0.2:\n","        noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.1)\n","        image = image + noise\n","\n","    # Mirroring (flip horizontal)\n","    if np.random.rand() < 0.5:\n","        image = tf.image.flip_left_right(image)\n","\n","    # Convierte la imagen aumentada de nuevo a un tensor\n","    augmented_image_tensor = tf.convert_to_tensor(image.numpy(), dtype=tf.float32)\n","\n","    return augmented_image_tensor"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"8HvJo8COcn4x"},"outputs":[],"source":["# Crea una nueva lista para almacenar los tensores de imágenes aumentados\n","imagen_tensor_aumentada = []\n","\n","# Itera a través de las filas del DataFrame y aplica la función de aumento de datos\n","for index, row in train.iterrows():\n","    if np.random.rand() < 0.38:\n","        imagen_tensor = row['Imagen']\n","        imagen_aumentada = data_augmentation(imagen_tensor)\n","        imagen_tensor_aumentada.append(imagen_aumentada)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"SdMZMqFYcn4y"},"outputs":[],"source":["train_augmentation = pd.DataFrame(columns=['Imagen', 'Guanaco'])\n","train_augmentation['Imagen'] = imagen_tensor_aumentada\n","train_augmentation['Guanaco'] = False"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"an0ZqnQlcn4y"},"outputs":[],"source":["train_augmentation= pd.concat([train, train_augmentation], ignore_index=True)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"WJdtoeLjcn4y","outputId":"61ad4588-7888-4209-cf5d-2e95e7470c6a"},"outputs":[{"data":{"text/plain":["Guanaco\n","False    1188\n","True     1180\n","Name: count, dtype: int64"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["train_augmentation['Guanaco'].value_counts()"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"ABm-6-S9cn4y"},"outputs":[],"source":["X_train = train_augmentation['Imagen']\n","y_train = train_augmentation['Guanaco']"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"fLCtpmGFcn4z"},"outputs":[],"source":["X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))"]},{"cell_type":"markdown","metadata":{"id":"Hf6BXZehcn4z"},"source":["## Descarga del modelo ResNet pre-entrenado:\n","Descarga el modelo ResNet pre-entrenado con pesos de ImageNet. Puedes hacerlo utilizando TensorFlow o Keras."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"tbJiADgVcn4z"},"outputs":[],"source":["input_shape = (150, 150, 3)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"FCNve5CScn4z"},"outputs":[],"source":["# Carga el modelo ResNet50 preentrenado con pesos de ImageNet \n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)"]},{"cell_type":"markdown","metadata":{"id":"dquYhTIllN48"},"source":["## Entrenamiento del modelo:\n","\n","Añade capas personalizadas en la parte superior del modelo VGG16 y entrena el modelo en tus datos utilizando el generador de datos. Asegúrate de congelar las capas base de VGG16 para que no se actualicen durante el entrenamiento."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"wiUDCsHmcn40"},"outputs":[],"source":["# Agregar capas personalizadas en la parte superior del modelo base\n","x = Flatten()(base_model.output)  # Flatten output to 1 dimension\n","x = Dense(1024, activation='relu')(x)  # Añade una capa con Relu activation\n","x = Dropout(0.2)(x)  # Añade un dropout rate de 0.2\n","\n","# # Agregar más capas densas\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.3)(x)\n","\n","# # Agregar más capas densas\n","# x = Dense(256, activation='relu')(x)\n","# x = Dropout(0.2)(x)\n","\n","# Capa de salida\n","predictions = Dense(1, activation='sigmoid')(x)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"MXs_FglPcn40"},"outputs":[],"source":["# Crear el modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"C54GZI5Scn40"},"outputs":[],"source":["# Congelar las capas del modelo base para el transfer learning\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"o-M7fJNtcn40"},"outputs":[],"source":["# Define the EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=5,           # Number of epochs with no improvement after which training will be stopped\n","    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",")"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"6A_yt6kBcn41"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n","WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"]}],"source":["# Compilar el modelo\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"-6mxEqjTcn41","outputId":"f623eb48-2298-4b17-a9db-0fc41c56527b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","72/72 [==============================] - 109s 1s/step - loss: 3.7744 - accuracy: 0.7238 - val_loss: 1.0171 - val_accuracy: 0.7912\n","Epoch 2/30\n","72/72 [==============================] - 100s 1s/step - loss: 0.6718 - accuracy: 0.8314 - val_loss: 0.5547 - val_accuracy: 0.8439\n","Epoch 3/30\n","72/72 [==============================] - 101s 1s/step - loss: 0.3732 - accuracy: 0.8801 - val_loss: 0.5620 - val_accuracy: 0.8351\n","Epoch 4/30\n","72/72 [==============================] - 101s 1s/step - loss: 0.2788 - accuracy: 0.9038 - val_loss: 0.4265 - val_accuracy: 0.8877\n","Epoch 5/30\n","72/72 [==============================] - 103s 1s/step - loss: 0.2284 - accuracy: 0.9139 - val_loss: 0.4635 - val_accuracy: 0.8772\n","Epoch 6/30\n","72/72 [==============================] - 101s 1s/step - loss: 0.1982 - accuracy: 0.9385 - val_loss: 0.4066 - val_accuracy: 0.8965\n","Epoch 7/30\n","72/72 [==============================] - 103s 1s/step - loss: 0.1539 - accuracy: 0.9504 - val_loss: 0.5191 - val_accuracy: 0.8877\n","Epoch 8/30\n","72/72 [==============================] - 100s 1s/step - loss: 0.1593 - accuracy: 0.9486 - val_loss: 0.5043 - val_accuracy: 0.8982\n","Epoch 9/30\n","72/72 [==============================] - 79s 1s/step - loss: 0.0979 - accuracy: 0.9649 - val_loss: 0.4160 - val_accuracy: 0.8860\n","Epoch 10/30\n","72/72 [==============================] - 40s 562ms/step - loss: 0.0895 - accuracy: 0.9679 - val_loss: 0.5626 - val_accuracy: 0.8912\n","Epoch 11/30\n","72/72 [==============================] - 42s 578ms/step - loss: 0.0717 - accuracy: 0.9767 - val_loss: 0.6719 - val_accuracy: 0.8877\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x29dc78ca0>"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# Entrenar el modelo con los datos de entrenamiento\n","model.fit(X_train_tf, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"5U_JFq4Icn41"},"outputs":[],"source":["# Guardar el modelo entrenado\n","model.save('ModelosFinales/modeloGuanacoRN50_v2.h5')"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["23/23 [==============================] - 21s 868ms/step\n"]}],"source":["y_proba = model.predict(X_test_tf)\n","y_pred = (y_proba >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"_Q68mlQScn42","outputId":"c79bc363-baf7-489c-f85b-d4e352b77d73"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9030898876404494\n","Recall: 0.941834451901566\n","Precision: 0.9073275862068966\n","Specificity: 0.8377358490566038\n"]}],"source":["# Calculamos Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Calculamos Recall\n","recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Recall: {recall}\")\n","\n","# Calculamos Precision\n","precision = precision_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Precision: {precision}\")\n","\n","# Calculamos Specificity\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","specificity = tn / (tn + fp)\n","print(f\"Specificity: {specificity}\")\n","\n","# Accuracy: 0.9143258426966292\n","# Recall: 0.9149888143176734\n","# Precision: 0.9467592592592593\n","# Specificity: 0.9132075471698113"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"XK62nQ-7cn42","outputId":"f5a9f6a9-0818-4e07-983a-c9301aa1c202"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision (AP): 0.9487897223595292\n"]}],"source":["# Calcular average precision\n","ap = average_precision_score(y_test, y_proba)\n","\n","print(\"Average Precision (AP):\", ap)"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"qIx71vHjcn43","outputId":"7309b0f9-19ab-4020-fdcb-9603a5717f9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","       False       0.72      0.76      0.74       136\n","        True       0.89      0.86      0.87       297\n","\n","    accuracy                           0.83       433\n","   macro avg       0.80      0.81      0.80       433\n","weighted avg       0.83      0.83      0.83       433\n","\n"]}],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"cm-lxoYicn43","outputId":"36c73d65-088d-4406-a7d4-9d8fd51708fc"},"outputs":[{"data":{"text/plain":["0.3125"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["(y_pred == 0).sum() / len(y_pred)"]},{"cell_type":"markdown","metadata":{"id":"5TkOE7uAcn43"},"source":["# Entrenamiento Categoria Especie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jcF5Mefcn43"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('ArchivosUtiles/trainingCategoria.pkl')\n","test = pd.read_pickle('ArchivosUtiles/testingCategoria.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B8vlLXGwcn49"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Categoria']\n","X_test = test['Imagen']\n","y_test = test['Categoria']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vHN3i8Dkcn49"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{},"source":["# Entrenamiento Aislado"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('ArchivosUtiles/trainingAislado.pkl')\n","test = pd.read_pickle('ArchivosUtiles/testingAislado.pkl')"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Aislado']\n","X_test = test['Imagen']\n","y_test = test['Aislado']"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{},"source":["## Balanceo"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"data":{"text/plain":["Aislado\n","0    829\n","1    829\n","Name: count, dtype: int64"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["y_train.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["## Descarga del modelo ResNet pre-entrenado:\n","Descarga el modelo ResNet pre-entrenado con pesos de ImageNet. Puedes hacerlo utilizando TensorFlow o Keras."]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["input_shape = (150, 150, 3)"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":["# Carga el modelo ResNet50 preentrenado con pesos de ImageNet \n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Entrenamiento del modelo:\n","\n","Añade capas personalizadas en la parte superior del modelo VGG16 y entrena el modelo en tus datos utilizando el generador de datos. Asegúrate de congelar las capas base de VGG16 para que no se actualicen durante el entrenamiento."]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[],"source":["# Agregar capas personalizadas en la parte superior del modelo base\n","x = Flatten()(base_model.output)  # Flatten output to 1 dimension\n","# x = Dense(1024, activation='relu')(x)  # Añade una capa con Relu activation\n","# x = Dropout(0.2)(x)  # Añade un dropout rate de 0.2\n","\n","# # Agregar más capas densas\n","# x = Dense(512, activation='relu')(x)\n","# x = Dropout(0.3)(x)\n","\n","# # Agregar más capas densas\n","# x = Dense(256, activation='relu')(x)\n","# x = Dropout(0.2)(x)\n","\n","# Capa de salida\n","predictions = Dense(1, activation='sigmoid')(x)"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[],"source":["# Crear el modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[],"source":["# Congelar las capas del modelo base para el transfer learning\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["# Define the EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=5,           # Number of epochs with no improvement after which training will be stopped\n","    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",")"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["# Compilar el modelo\n","model.compile(optimizer=Adam(learning_rate=0.005), loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","42/42 [==============================] - 90s 2s/step - loss: 9.2330 - accuracy: 0.6214 - val_loss: 11.4443 - val_accuracy: 0.6084\n","Epoch 2/30\n","42/42 [==============================] - 81s 2s/step - loss: 3.5254 - accuracy: 0.7903 - val_loss: 6.4313 - val_accuracy: 0.7048\n","Epoch 3/30\n","42/42 [==============================] - 83s 2s/step - loss: 2.0499 - accuracy: 0.8605 - val_loss: 8.7943 - val_accuracy: 0.6898\n","Epoch 4/30\n","42/42 [==============================] - 83s 2s/step - loss: 2.6269 - accuracy: 0.8333 - val_loss: 8.2979 - val_accuracy: 0.7139\n","Epoch 5/30\n","42/42 [==============================] - 75s 2s/step - loss: 1.7189 - accuracy: 0.8884 - val_loss: 9.1742 - val_accuracy: 0.6717\n","Epoch 6/30\n","42/42 [==============================] - 59s 1s/step - loss: 0.8422 - accuracy: 0.9359 - val_loss: 8.9183 - val_accuracy: 0.6837\n","Epoch 7/30\n","42/42 [==============================] - 63s 2s/step - loss: 0.4198 - accuracy: 0.9578 - val_loss: 8.2148 - val_accuracy: 0.7199\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fe5d010f7f0>"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["# Entrenar el modelo con los datos de entrenamiento\n","model.fit(X_train_tf, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":["# Guardar el modelo entrenado\n","model.save('ModelosFinales/modeloAisladoRN50.h5')"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["13/13 [==============================] - 9s 618ms/step\n"]}],"source":["y_proba = model.predict(X_test_tf)\n","y_pred = (y_proba >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.6096385542168675\n","Recall: 0.7681159420289855\n","Precision: 0.5824175824175825\n","Specificity: 0.4519230769230769\n"]}],"source":["# Calculamos Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Calculamos Recall\n","recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Recall: {recall}\")\n","\n","# Calculamos Precision\n","precision = precision_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Precision: {precision}\")\n","\n","# Calculamos Specificity\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","specificity = tn / (tn + fp)\n","print(f\"Specificity: {specificity}\")\n","\n","# Accuracy: 0.6602409638554216\n","# Recall: 0.5845410628019324\n","# Precision: 0.6875\n","# Specificity: 0.7355769230769231"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision (AP): 0.6794296005186735\n"]}],"source":["# Calcular average precision\n","ap = average_precision_score(y_test, y_proba)\n","\n","print(\"Average Precision (AP):\", ap)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","       False       0.72      0.76      0.74       136\n","        True       0.89      0.86      0.87       297\n","\n","    accuracy                           0.83       433\n","   macro avg       0.80      0.81      0.80       433\n","weighted avg       0.83      0.83      0.83       433\n","\n"]}],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["0.3125"]},"metadata":{},"output_type":"display_data"}],"source":["(y_pred == 0).sum() / len(y_pred)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
