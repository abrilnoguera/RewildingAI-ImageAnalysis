{"cells":[{"cell_type":"markdown","metadata":{"id":"9QgWy64mefKs"},"source":["Para replicar el referenciamiento de ImageNet en tu propio dataset de imágenes almacenado en Amazon S3 y ejecutar la transferencia de aprendizaje con ResNet, debes seguir varios pasos. Aquí tienes una guía general sobre cómo hacerlo:\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1037,"status":"ok","timestamp":1696793001831,"user":{"displayName":"LUCAS ARBUES","userId":"10189924890821610700"},"user_tz":180},"id":"--MGqE0-ejHh"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-10-09 11:50:33.752075: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n","Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"]}],"source":["# Librerías estándar\n","import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from io import BytesIO\n","\n","# TensorFlow y Keras\n","import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import (Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D, MaxPooling2D, Reshape)\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n","\n","# Otras librerías\n","import os\n","import boto3\n","from PIL import Image\n","from sklearn.metrics import (accuracy_score, auc, average_precision_score, classification_report, \n","                             confusion_matrix, precision_score, recall_score)\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"SilxVuzGcn4e"},"source":["# Entrenamiento Animal y No Animal"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"k2NXUxbkcn4e"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('trainingAnimal.pkl')\n","test = pd.read_pickle('testingAnimal.pkl')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xaXOJxH9cn4e"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Animal']\n","X_test = test['Imagen']\n","y_test = test['Animal']"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"rVp6rm74cn4e"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{"id":"XMnvI64Nf_sQ"},"source":["## Descarga del modelo ResNet50 pre-entrenado:\n","Descarga el modelo ResNet50 pre-entrenado con pesos de ImageNet. Puedes hacerlo utilizando TensorFlow o Keras."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"XJTxGKtGgdz1"},"outputs":[],"source":["input_shape = (150, 150, 3)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"BIgdNTQTgfgs"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 12s 0us/step\n"]}],"source":["# Carga el modelo ResNet50 preentrenado con pesos de ImageNet \n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)"]},{"cell_type":"markdown","metadata":{"id":"V6GuJ5YOgNHW"},"source":["## Generador de datos:\n","\n","Utiliza un generador de datos de Keras para cargar y preprocesar tus imágenes desde S3. Debes proporcionar la ruta a tus imágenes en S3 y etiquetas correspondientes. Aquí un ejemplo de cómo configurar un generador de datos:"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"7Sk25YR_kb8U"},"outputs":[],"source":["# Número de clases en tu conjunto de datos\n","num_classes = len(y_train.unique())"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"IL-a9_xbkvZn"},"outputs":[],"source":["# Tamaño del lote (batch size) que deseas utilizar durante el entrenamiento\n","batch_size = 32"]},{"cell_type":"markdown","metadata":{"id":"LpvkgxD3cn4g"},"source":["## Entrenamiento del modelo:\n","\n","Añade capas personalizadas en la parte superior del modelo VGG16 y entrena el modelo en tus datos utilizando el generador de datos. Asegúrate de congelar las capas base de ResNet para que no se actualicen durante el entrenamiento."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"CD74A8wCcn4g"},"outputs":[],"source":["# Agregar capas personalizadas en la parte superior del modelo base\n","x = Flatten()(base_model.output) #Flatten output to 1 dimension\n","x = Dense(1024,activation='relu')(x) #Añade una layer con Relu activation\n","x = Dropout(0.2)(x) #Añade un dropout rate de 0.2\n","predictions = Dense(1, activation = 'sigmoid')(x)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"BrlcuY_mcn4g"},"outputs":[],"source":["# Crear el modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"CcZSIgh9cn4h"},"outputs":[],"source":["# Congelar las capas del modelo base para el transfer learning\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"bHbMQBbpcn4h"},"outputs":[],"source":["# Compilar el modelo\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"5c-f-G3Hcn4h"},"outputs":[],"source":["# Define the EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=5,           # Number of epochs with no improvement after which training will be stopped\n","    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"mPR7VFsNcn4i","outputId":"473b88a6-df57-4b6f-c5d4-35abe18326a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","119/119 [==============================] - 152s 1s/step - loss: 2.1522 - accuracy: 0.9505 - val_loss: 2.4049 - val_accuracy: 0.9663\n","Epoch 2/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.7180 - accuracy: 0.9797 - val_loss: 2.4509 - val_accuracy: 0.9663\n","Epoch 3/30\n","119/119 [==============================] - 147s 1s/step - loss: 0.5401 - accuracy: 0.9784 - val_loss: 2.0228 - val_accuracy: 0.9611\n","Epoch 4/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.2824 - accuracy: 0.9860 - val_loss: 2.1384 - val_accuracy: 0.9611\n","Epoch 5/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.2759 - accuracy: 0.9863 - val_loss: 1.3570 - val_accuracy: 0.9463\n","Epoch 6/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.1690 - accuracy: 0.9881 - val_loss: 1.3414 - val_accuracy: 0.9611\n","Epoch 7/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.1566 - accuracy: 0.9897 - val_loss: 1.0647 - val_accuracy: 0.9653\n","Epoch 8/30\n","119/119 [==============================] - 142s 1s/step - loss: 0.1061 - accuracy: 0.9910 - val_loss: 0.7029 - val_accuracy: 0.9579\n","Epoch 9/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.0682 - accuracy: 0.9926 - val_loss: 0.5232 - val_accuracy: 0.9526\n","Epoch 10/30\n","119/119 [==============================] - 147s 1s/step - loss: 0.0373 - accuracy: 0.9937 - val_loss: 0.5017 - val_accuracy: 0.9505\n","Epoch 11/30\n","119/119 [==============================] - 148s 1s/step - loss: 0.0347 - accuracy: 0.9932 - val_loss: 0.4686 - val_accuracy: 0.9537\n","Epoch 12/30\n","119/119 [==============================] - 146s 1s/step - loss: 0.0804 - accuracy: 0.9892 - val_loss: 0.8011 - val_accuracy: 0.9611\n","Epoch 13/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.0640 - accuracy: 0.9908 - val_loss: 0.5908 - val_accuracy: 0.9558\n","Epoch 14/30\n","119/119 [==============================] - 152s 1s/step - loss: 0.0633 - accuracy: 0.9926 - val_loss: 0.6939 - val_accuracy: 0.9663\n","Epoch 15/30\n","119/119 [==============================] - 157s 1s/step - loss: 0.0593 - accuracy: 0.9889 - val_loss: 0.6389 - val_accuracy: 0.9589\n","Epoch 16/30\n","119/119 [==============================] - 141s 1s/step - loss: 0.0561 - accuracy: 0.9913 - val_loss: 0.4477 - val_accuracy: 0.9611\n","Epoch 17/30\n","119/119 [==============================] - 145s 1s/step - loss: 0.0450 - accuracy: 0.9910 - val_loss: 0.5219 - val_accuracy: 0.9568\n","Epoch 18/30\n","119/119 [==============================] - 211s 2s/step - loss: 0.0475 - accuracy: 0.9926 - val_loss: 0.7946 - val_accuracy: 0.9663\n","Epoch 19/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.1119 - accuracy: 0.9866 - val_loss: 1.1067 - val_accuracy: 0.9632\n","Epoch 20/30\n","119/119 [==============================] - 144s 1s/step - loss: 0.1473 - accuracy: 0.9881 - val_loss: 0.8134 - val_accuracy: 0.9621\n","Epoch 21/30\n","119/119 [==============================] - 159s 1s/step - loss: 0.1366 - accuracy: 0.9884 - val_loss: 1.0215 - val_accuracy: 0.9600\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fdfb455bfa0>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Entrena el modelo con los datos de entrenamiento\n","model.fit(X_train_tf, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"w2NsNXwtcn4i"},"outputs":[],"source":["# Guardar el modelo entrenado\n","model.save('modeloAnimalRN50.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8L6vW1wWcn4j","outputId":"ed9d69a1-af32-45c1-9720-a766db10b1ce"},"outputs":[],"source":["y_proba = model.predict(X_test_tf)\n","y_pred = (y_proba >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z30PY8nLcn4j","outputId":"a10da620-0e63-42f5-f8a6-d10b2a3bc6f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9713563605728728\n","Recall: 0.9838709677419355\n","Specificity: 0.9576719576719577\n"]}],"source":["# Calculamos Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Calculamos Recall\n","recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Recall: {recall}\")\n","\n","# Calculamos Specificity\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","specificity = tn / (tn + fp)\n","print(f\"Specificity: {specificity}\")"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"RI46LS2Acn4k","outputId":"8b2409c4-fd1d-42a1-8085-811bd8841917"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision (AP): 0.9829587558124374\n"]}],"source":["# Calcular average precision\n","ap = average_precision_score(y_test, y_proba)\n","\n","print(\"Average Precision (AP):\", ap)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Za6vMqCCcn4k","outputId":"ff12b0d8-c471-48cf-f5b0-d76fe5b7d5c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.98      0.96      0.97       567\n","           1       0.96      0.98      0.97       620\n","\n","    accuracy                           0.97      1187\n","   macro avg       0.97      0.97      0.97      1187\n","weighted avg       0.97      0.97      0.97      1187\n","\n"]}],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"J0IgauQCcn4l"},"source":["# Entrenamiento Guanaco y No Guanaco"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"8N0g-ZY5cn4l"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('trainingGuanaco.pkl')\n","test = pd.read_pickle('testingGuanaco.pkl')"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"MLkzZqP4cn4l"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Guanaco']\n","X_test = test['Imagen']\n","y_test = test['Guanaco']"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"15bqeJA_cn4v"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{"id":"uJPIz6-4cn4w"},"source":["## Balanceo"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"WpEMtRrbcn4w","outputId":"baf9c258-3298-4497-85c5-00f9adbabb92"},"outputs":[{"data":{"text/plain":["Guanaco\n","True     1187\n","False     541\n","Name: count, dtype: int64"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["y_train.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"5oi8oQWPcn4w"},"source":["La base esta desbalanceada ya que existen muchos mas guanacos que otros animales. Para resolver esto se somete al resto de los animales a tecnicas de *Data Augmentation*"]},{"cell_type":"markdown","metadata":{"id":"RZZYJ2DRcn4x"},"source":["Data Augmentation: make training set larger by applying transformations. More information to learn from.\n","- Brightness and Contrast adjustments\n","- Rotations\n","- Gaussian noise\n","- Mirroring"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"XG4EE2FMcn4x"},"outputs":[],"source":["def data_augmentation(image_tensor):\n","\n","    # Convierte el tensor de imagen a una imagen TensorFlow\n","    image = tf.convert_to_tensor(image_tensor, dtype=tf.float32)\n","\n","    # Brightness and Contrast adjustments\n","    if np.random.rand() < 0.8:\n","        image = tf.image.adjust_brightness(image, delta=0.2)  # Cambiar el brillo\n","        image = tf.image.adjust_contrast(image, contrast_factor=1.2)  # Cambiar el contraste\n","\n","    # Rotations\n","    if np.random.rand() < 0.7:\n","        degrees = np.random.uniform(-10, 10)  # Rotación aleatoria entre -10 y 10 grados\n","        degrees = int(round(degrees))  # Redondea los grados a un entero\n","        image = tf.image.rot90(image, k=degrees // 90)  # Rotar la imagen\n","\n","    # Gaussian noise\n","    if np.random.rand() < 0.2:\n","        noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.1)\n","        image = image + noise\n","\n","    # Mirroring (flip horizontal)\n","    if np.random.rand() < 0.5:\n","        image = tf.image.flip_left_right(image)\n","\n","    # Convierte la imagen aumentada de nuevo a un tensor\n","    augmented_image_tensor = tf.convert_to_tensor(image.numpy(), dtype=tf.float32)\n","\n","    return augmented_image_tensor"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"8HvJo8COcn4x"},"outputs":[],"source":["# Crea una nueva lista para almacenar los tensores de imágenes aumentados\n","imagen_tensor_aumentada = []\n","\n","# Itera a través de las filas del DataFrame y aplica la función de aumento de datos\n","for index, row in train.iterrows():\n","    if np.random.rand() < 0.38:\n","        imagen_tensor = row['Imagen']\n","        imagen_aumentada = data_augmentation(imagen_tensor)\n","        imagen_tensor_aumentada.append(imagen_aumentada)"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"SdMZMqFYcn4y"},"outputs":[],"source":["train_augmentation = pd.DataFrame(columns=['Imagen', 'Guanaco'])\n","train_augmentation['Imagen'] = imagen_tensor_aumentada\n","train_augmentation['Guanaco'] = False"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"an0ZqnQlcn4y"},"outputs":[],"source":["train_augmentation= pd.concat([train, train_augmentation], ignore_index=True)"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"WJdtoeLjcn4y","outputId":"61ad4588-7888-4209-cf5d-2e95e7470c6a"},"outputs":[{"data":{"text/plain":["Guanaco\n","False    1200\n","True     1187\n","Name: count, dtype: int64"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["train_augmentation['Guanaco'].value_counts()"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"ABm-6-S9cn4y"},"outputs":[],"source":["X_train = train_augmentation['Imagen']\n","y_train = train_augmentation['Guanaco']"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"fLCtpmGFcn4z"},"outputs":[],"source":["X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))"]},{"cell_type":"markdown","metadata":{"id":"Hf6BXZehcn4z"},"source":["## Descarga del modelo VGG16 pre-entrenado:\n","Descarga el modelo VGG16 pre-entrenado con pesos de ImageNet. Puedes hacerlo utilizando TensorFlow o Keras."]},{"cell_type":"code","execution_count":83,"metadata":{"id":"tbJiADgVcn4z"},"outputs":[],"source":["input_shape = (150, 150, 3)"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"FCNve5CScn4z"},"outputs":[],"source":["# Carga el modelo ResNet50 preentrenado con pesos de ImageNet \n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)"]},{"cell_type":"markdown","metadata":{"id":"dquYhTIllN48"},"source":["## Entrenamiento del modelo:\n","\n","Añade capas personalizadas en la parte superior del modelo VGG16 y entrena el modelo en tus datos utilizando el generador de datos. Asegúrate de congelar las capas base de VGG16 para que no se actualicen durante el entrenamiento."]},{"cell_type":"code","execution_count":85,"metadata":{"id":"wiUDCsHmcn40"},"outputs":[],"source":["# Agregar capas personalizadas en la parte superior del modelo base\n","x = Flatten()(base_model.output)  # Flatten output to 1 dimension\n","# x = Dense(1024, activation='relu')(x)  # Añade una capa con Relu activation\n","# x = Dropout(0.2)(x)  # Añade un dropout rate de 0.2\n","\n","# # Agregar más capas densas\n","# x = Dense(512, activation='relu')(x)\n","# x = Dropout(0.3)(x)\n","\n","# # Agregar más capas densas\n","# x = Dense(256, activation='relu')(x)\n","# x = Dropout(0.2)(x)\n","\n","# Capa de salida\n","predictions = Dense(1, activation='sigmoid')(x)"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"MXs_FglPcn40"},"outputs":[],"source":["# Crear el modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"C54GZI5Scn40"},"outputs":[],"source":["# Congelar las capas del modelo base para el transfer learning\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"o-M7fJNtcn40"},"outputs":[],"source":["# Define the EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=5,           # Number of epochs with no improvement after which training will be stopped\n","    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",")"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"6A_yt6kBcn41"},"outputs":[],"source":["# Compilar el modelo\n","model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":90,"metadata":{"id":"-6mxEqjTcn41","outputId":"f623eb48-2298-4b17-a9db-0fc41c56527b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","60/60 [==============================] - 142s 2s/step - loss: 0.9313 - accuracy: 0.7260 - val_loss: 1.2911 - val_accuracy: 0.7197\n","Epoch 2/30\n","60/60 [==============================] - 154s 3s/step - loss: 0.4006 - accuracy: 0.8607 - val_loss: 1.0035 - val_accuracy: 0.7992\n","Epoch 3/30\n","60/60 [==============================] - 167s 3s/step - loss: 0.2827 - accuracy: 0.9005 - val_loss: 1.2139 - val_accuracy: 0.7741\n","Epoch 4/30\n","60/60 [==============================] - 151s 3s/step - loss: 0.1478 - accuracy: 0.9471 - val_loss: 1.0425 - val_accuracy: 0.7887\n","Epoch 5/30\n","60/60 [==============================] - 165s 3s/step - loss: 0.1113 - accuracy: 0.9649 - val_loss: 1.6127 - val_accuracy: 0.7280\n","Epoch 6/30\n","60/60 [==============================] - 149s 2s/step - loss: 0.1187 - accuracy: 0.9591 - val_loss: 1.6764 - val_accuracy: 0.7218\n","Epoch 7/30\n","60/60 [==============================] - 122s 2s/step - loss: 0.0992 - accuracy: 0.9680 - val_loss: 1.4536 - val_accuracy: 0.7448\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7ff1ad241490>"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["# Entrenar el modelo con los datos de entrenamiento\n","model.fit(X_train_tf, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"5U_JFq4Icn41"},"outputs":[],"source":["# Guardar el modelo entrenado\n","model.save('modeloGuanacoRN50.h5')"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["14/14 [==============================] - 24s 2s/step\n"]}],"source":["y_proba = model.predict(X_test_tf)\n","y_pred = (y_proba >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"_Q68mlQScn42","outputId":"c79bc363-baf7-489c-f85b-d4e352b77d73"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.789838337182448\n","Recall: 0.761744966442953\n","Precision: 0.9190283400809717\n","Specificity: 0.8518518518518519\n"]}],"source":["# Calculamos Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Calculamos Recall\n","recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Recall: {recall}\")\n","\n","# Calculamos Precision\n","precision = precision_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Precision: {precision}\")\n","\n","# Calculamos Specificity\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","specificity = tn / (tn + fp)\n","print(f\"Specificity: {specificity}\")\n","\n","# Accuracy: 0.8290993071593533\n","# Recall: 0.8619528619528619\n","# Precision: 0.8858131487889274\n","# Specificity: 0.7573529411764706"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"XK62nQ-7cn42","outputId":"f5a9f6a9-0818-4e07-983a-c9301aa1c202"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision (AP): 0.8960072957860057\n"]}],"source":["# Calcular average precision\n","ap = average_precision_score(y_test, y_proba)\n","\n","print(\"Average Precision (AP):\", ap)"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"qIx71vHjcn43","outputId":"7309b0f9-19ab-4020-fdcb-9603a5717f9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","       False       0.72      0.76      0.74       136\n","        True       0.89      0.86      0.87       297\n","\n","    accuracy                           0.83       433\n","   macro avg       0.80      0.81      0.80       433\n","weighted avg       0.83      0.83      0.83       433\n","\n"]}],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cm-lxoYicn43","outputId":"36c73d65-088d-4406-a7d4-9d8fd51708fc"},"outputs":[{"data":{"text/plain":["0.7780320366132724"]},"execution_count":352,"metadata":{},"output_type":"execute_result"}],"source":["(y_pred == 0).sum() / len(y_pred)"]},{"cell_type":"markdown","metadata":{"id":"5TkOE7uAcn43"},"source":["# Entrenamiento Categoria Especie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jcF5Mefcn43"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('trainingCategoria.pkl')\n","test = pd.read_pickle('testingCategoria.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B8vlLXGwcn49"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Categoria']\n","X_test = test['Imagen']\n","y_test = test['Categoria']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vHN3i8Dkcn49"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
