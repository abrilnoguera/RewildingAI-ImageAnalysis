{"cells":[{"cell_type":"markdown","metadata":{"id":"9QgWy64mefKs"},"source":["Para replicar el referenciamiento de ImageNet en tu propio dataset de imágenes almacenado en Amazon S3 y ejecutar la transferencia de aprendizaje con InceptionV3, debes seguir varios pasos. Aquí tienes una guía general sobre cómo hacerlo:\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1037,"status":"ok","timestamp":1696793001831,"user":{"displayName":"LUCAS ARBUES","userId":"10189924890821610700"},"user_tz":180},"id":"--MGqE0-ejHh"},"outputs":[{"name":"stdout","output_type":"stream","text":["Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n","Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"]},{"name":"stderr","output_type":"stream","text":["2023-10-12 18:32:57.653747: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["# Librerías estándar\n","import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from io import BytesIO\n","\n","# TensorFlow y Keras\n","import tensorflow as tf\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import (Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D, MaxPooling2D, Reshape)\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n","\n","# Otras librerías\n","import os\n","import boto3\n","from PIL import Image\n","from sklearn.metrics import (accuracy_score, auc, average_precision_score, classification_report, \n","                             confusion_matrix, precision_score, recall_score)\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"SilxVuzGcn4e"},"source":["# Entrenamiento Animal y No Animal"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"k2NXUxbkcn4e"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('trainingAnimal.pkl')\n","test = pd.read_pickle('testingAnimal.pkl')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xaXOJxH9cn4e"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Animal']\n","X_test = test['Imagen']\n","y_test = test['Animal']"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"rVp6rm74cn4e"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{"id":"XMnvI64Nf_sQ"},"source":["## Descarga del modelo InceptionV3 pre-entrenado:\n","Descarga el modelo InceptionV3 pre-entrenado con pesos de ImageNet. Puedes hacerlo utilizando TensorFlow o Keras."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"XJTxGKtGgdz1"},"outputs":[],"source":["input_shape = (150, 150, 3)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"BIgdNTQTgfgs"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 9s 0us/step\n"]}],"source":["# Carga el modelo InceptionV3 preentrenado con pesos de ImageNet (no incluye las capas densas superiores)\n","base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)"]},{"cell_type":"markdown","metadata":{"id":"V6GuJ5YOgNHW"},"source":["## Generador de datos:\n","\n","Utiliza un generador de datos de Keras para cargar y preprocesar tus imágenes desde S3. Debes proporcionar la ruta a tus imágenes en S3 y etiquetas correspondientes. Aquí un ejemplo de cómo configurar un generador de datos:"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"7Sk25YR_kb8U"},"outputs":[],"source":["# Número de clases en tu conjunto de datos\n","num_classes = len(y_train.unique())"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"IL-a9_xbkvZn"},"outputs":[],"source":["# Tamaño del lote (batch size) que deseas utilizar durante el entrenamiento\n","batch_size = 32"]},{"cell_type":"markdown","metadata":{"id":"LpvkgxD3cn4g"},"source":["## Entrenamiento del modelo:\n","\n","Añade capas personalizadas en la parte superior del modelo InceptionV3 y entrena el modelo en tus datos utilizando el generador de datos. Asegúrate de congelar las capas base de InceptionV3 para que no se actualicen durante el entrenamiento."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"CD74A8wCcn4g"},"outputs":[],"source":["# Agregar capas personalizadas en la parte superior del modelo base\n","x = Flatten()(base_model.output) #Flatten output to 1 dimension\n","x = Dense(1024,activation='relu')(x) #Añade una layer con Relu activation\n","x = Dropout(0.2)(x) #Añade un dropout rate de 0.2\n","predictions = Dense(1, activation = 'sigmoid')(x)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"BrlcuY_mcn4g"},"outputs":[],"source":["# Crear el modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"CcZSIgh9cn4h"},"outputs":[],"source":["# Congelar las capas del modelo base para el transfer learning\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"bHbMQBbpcn4h"},"outputs":[],"source":["# Compilar el modelo\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"5c-f-G3Hcn4h"},"outputs":[],"source":["# Define the EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=5,           # Number of epochs with no improvement after which training will be stopped\n","    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"mPR7VFsNcn4i","outputId":"473b88a6-df57-4b6f-c5d4-35abe18326a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","119/119 [==============================] - 66s 518ms/step - loss: 43.1880 - accuracy: 0.8454 - val_loss: 5.8533 - val_accuracy: 0.9221\n","Epoch 2/30\n","119/119 [==============================] - 57s 480ms/step - loss: 1.9160 - accuracy: 0.9339 - val_loss: 1.8785 - val_accuracy: 0.7916\n","Epoch 3/30\n","119/119 [==============================] - 58s 488ms/step - loss: 0.3251 - accuracy: 0.9434 - val_loss: 0.2038 - val_accuracy: 0.9453\n","Epoch 4/30\n","119/119 [==============================] - 91s 763ms/step - loss: 0.1279 - accuracy: 0.9605 - val_loss: 0.2401 - val_accuracy: 0.9316\n","Epoch 5/30\n","119/119 [==============================] - 233s 2s/step - loss: 0.1045 - accuracy: 0.9663 - val_loss: 0.2160 - val_accuracy: 0.9453\n","Epoch 6/30\n","119/119 [==============================] - 294s 2s/step - loss: 0.0937 - accuracy: 0.9692 - val_loss: 0.2005 - val_accuracy: 0.9453\n","Epoch 7/30\n","119/119 [==============================] - 233s 2s/step - loss: 0.0964 - accuracy: 0.9665 - val_loss: 0.1737 - val_accuracy: 0.9484\n","Epoch 8/30\n","119/119 [==============================] - 205s 2s/step - loss: 0.1118 - accuracy: 0.9613 - val_loss: 0.1699 - val_accuracy: 0.9558\n","Epoch 9/30\n","119/119 [==============================] - 195s 2s/step - loss: 0.0966 - accuracy: 0.9692 - val_loss: 0.2302 - val_accuracy: 0.9442\n","Epoch 10/30\n","119/119 [==============================] - 191s 2s/step - loss: 0.1139 - accuracy: 0.9610 - val_loss: 0.2081 - val_accuracy: 0.9558\n","Epoch 11/30\n","119/119 [==============================] - 164s 1s/step - loss: 0.1154 - accuracy: 0.9629 - val_loss: 0.2875 - val_accuracy: 0.9305\n","Epoch 12/30\n","119/119 [==============================] - 128s 1s/step - loss: 0.1347 - accuracy: 0.9505 - val_loss: 0.2631 - val_accuracy: 0.9126\n","Epoch 13/30\n","119/119 [==============================] - 124s 1s/step - loss: 0.1559 - accuracy: 0.9410 - val_loss: 0.1946 - val_accuracy: 0.9442\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7faf98c64e20>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Entrena el modelo con los datos de entrenamiento\n","model.fit(X_train_tf, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"w2NsNXwtcn4i"},"outputs":[],"source":["# Guardar el modelo entrenado\n","model.save('modeloAnimalIV3.h5')"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"8L6vW1wWcn4j","outputId":"ed9d69a1-af32-45c1-9720-a766db10b1ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["38/38 [==============================] - 34s 830ms/step\n"]}],"source":["y_proba = model.predict(X_test_tf)\n","y_pred = (y_proba >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"z30PY8nLcn4j","outputId":"a10da620-0e63-42f5-f8a6-d10b2a3bc6f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9604043807919124\n","Recall: 0.9854838709677419\n","Specificity: 0.9329805996472663\n"]}],"source":["# Calculamos Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Calculamos Recall\n","recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Recall: {recall}\")\n","\n","# Calculamos Specificity\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","specificity = tn / (tn + fp)\n","print(f\"Specificity: {specificity}\")"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"RI46LS2Acn4k","outputId":"8b2409c4-fd1d-42a1-8085-811bd8841917"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision (AP): 0.966844633225649\n"]}],"source":["# Calcular average precision\n","ap = average_precision_score(y_test, y_proba)\n","\n","print(\"Average Precision (AP):\", ap)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Za6vMqCCcn4k","outputId":"ff12b0d8-c471-48cf-f5b0-d76fe5b7d5c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.98      0.95      0.97       567\n","           1       0.96      0.99      0.97       620\n","\n","    accuracy                           0.97      1187\n","   macro avg       0.97      0.97      0.97      1187\n","weighted avg       0.97      0.97      0.97      1187\n","\n"]}],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"J0IgauQCcn4l"},"source":["# Entrenamiento Guanaco y No Guanaco"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"8N0g-ZY5cn4l"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('trainingGuanaco.pkl')\n","test = pd.read_pickle('testingGuanaco.pkl')"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"MLkzZqP4cn4l"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Guanaco']\n","X_test = test['Imagen']\n","y_test = test['Guanaco']"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"15bqeJA_cn4v"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]},{"cell_type":"markdown","metadata":{"id":"uJPIz6-4cn4w"},"source":["## Balanceo"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"WpEMtRrbcn4w","outputId":"baf9c258-3298-4497-85c5-00f9adbabb92"},"outputs":[{"data":{"text/plain":["Guanaco\n","True     1187\n","False     541\n","Name: count, dtype: int64"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["y_train.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"5oi8oQWPcn4w"},"source":["La base esta desbalanceada ya que existen muchos mas guanacos que otros animales. Para resolver esto se somete al resto de los animales a tecnicas de *Data Augmentation*"]},{"cell_type":"markdown","metadata":{"id":"RZZYJ2DRcn4x"},"source":["Data Augmentation: make training set larger by applying transformations. More information to learn from.\n","- Brightness and Contrast adjustments\n","- Rotations\n","- Gaussian noise\n","- Mirroring"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"XG4EE2FMcn4x"},"outputs":[],"source":["def data_augmentation(image_tensor):\n","\n","    # Convierte el tensor de imagen a una imagen TensorFlow\n","    image = tf.convert_to_tensor(image_tensor, dtype=tf.float32)\n","\n","    # Brightness and Contrast adjustments\n","    if np.random.rand() < 0.8:\n","        image = tf.image.adjust_brightness(image, delta=0.2)  # Cambiar el brillo\n","        image = tf.image.adjust_contrast(image, contrast_factor=1.2)  # Cambiar el contraste\n","\n","    # Rotations\n","    if np.random.rand() < 0.7:\n","        degrees = np.random.uniform(-10, 10)  # Rotación aleatoria entre -10 y 10 grados\n","        degrees = int(round(degrees))  # Redondea los grados a un entero\n","        image = tf.image.rot90(image, k=degrees // 90)  # Rotar la imagen\n","\n","    # Gaussian noise\n","    if np.random.rand() < 0.2:\n","        noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.1)\n","        image = image + noise\n","\n","    # Mirroring (flip horizontal)\n","    if np.random.rand() < 0.5:\n","        image = tf.image.flip_left_right(image)\n","\n","    # Convierte la imagen aumentada de nuevo a un tensor\n","    augmented_image_tensor = tf.convert_to_tensor(image.numpy(), dtype=tf.float32)\n","\n","    return augmented_image_tensor"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"8HvJo8COcn4x"},"outputs":[],"source":["# Crea una nueva lista para almacenar los tensores de imágenes aumentados\n","imagen_tensor_aumentada = []\n","\n","# Itera a través de las filas del DataFrame y aplica la función de aumento de datos\n","for index, row in train.iterrows():\n","    if np.random.rand() < 0.38:\n","        imagen_tensor = row['Imagen']\n","        imagen_aumentada = data_augmentation(imagen_tensor)\n","        imagen_tensor_aumentada.append(imagen_aumentada)"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"SdMZMqFYcn4y"},"outputs":[],"source":["train_augmentation = pd.DataFrame(columns=['Imagen', 'Guanaco'])\n","train_augmentation['Imagen'] = imagen_tensor_aumentada\n","train_augmentation['Guanaco'] = False"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"an0ZqnQlcn4y"},"outputs":[],"source":["train_augmentation= pd.concat([train, train_augmentation], ignore_index=True)"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"WJdtoeLjcn4y","outputId":"61ad4588-7888-4209-cf5d-2e95e7470c6a"},"outputs":[{"data":{"text/plain":["Guanaco\n","False    1199\n","True     1187\n","Name: count, dtype: int64"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["train_augmentation['Guanaco'].value_counts()"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"ABm-6-S9cn4y"},"outputs":[],"source":["X_train = train_augmentation['Imagen']\n","y_train = train_augmentation['Guanaco']"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"fLCtpmGFcn4z"},"outputs":[],"source":["X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))"]},{"cell_type":"markdown","metadata":{"id":"Hf6BXZehcn4z"},"source":["## Descarga del modelo VGG16 pre-entrenado:\n","Descarga el modelo VGG16 pre-entrenado con pesos de ImageNet. Puedes hacerlo utilizando TensorFlow o Keras."]},{"cell_type":"code","execution_count":77,"metadata":{"id":"tbJiADgVcn4z"},"outputs":[],"source":["input_shape = (150, 150, 3)"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"FCNve5CScn4z"},"outputs":[],"source":["# Carga el modelo InceptionV3 preentrenado con pesos de ImageNet (no incluye las capas densas superiores)\n","base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)"]},{"cell_type":"markdown","metadata":{"id":"dquYhTIllN48"},"source":["## Entrenamiento del modelo:\n","\n","Añade capas personalizadas en la parte superior del modelo VGG16 y entrena el modelo en tus datos utilizando el generador de datos. Asegúrate de congelar las capas base de VGG16 para que no se actualicen durante el entrenamiento."]},{"cell_type":"code","execution_count":79,"metadata":{"id":"wiUDCsHmcn40"},"outputs":[],"source":["# Agregar capas personalizadas en la parte superior del modelo base\n","x = Flatten()(base_model.output)  # Flatten output to 1 dimension\n","# x = Dense(1024, activation='relu')(x)  # Añade una capa con Relu activation\n","# x = Dropout(0.2)(x)  # Añade un dropout rate de 0.2\n","\n","# # Agregar más capas densas\n","# x = Dense(512, activation='relu')(x)\n","# x = Dropout(0.3)(x)\n","\n","# # Agregar más capas densas\n","# x = Dense(256, activation='relu')(x)\n","# x = Dropout(0.2)(x)\n","\n","\n","# Capa de salida\n","predictions = Dense(1, activation='sigmoid')(x)"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"MXs_FglPcn40"},"outputs":[],"source":["# Crear el modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"C54GZI5Scn40"},"outputs":[],"source":["# Congelar las capas del modelo base para el transfer learning\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"o-M7fJNtcn40"},"outputs":[],"source":["# Define the EarlyStopping callback\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=5,           # Number of epochs with no improvement after which training will be stopped\n","    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",")"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"6A_yt6kBcn41"},"outputs":[],"source":["# Compilar el modelo\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"-6mxEqjTcn41","outputId":"f623eb48-2298-4b17-a9db-0fc41c56527b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","60/60 [==============================] - 92s 1s/step - loss: 6.9560 - accuracy: 0.5954 - val_loss: 5.4525 - val_accuracy: 0.4770\n","Epoch 2/30\n","60/60 [==============================] - 77s 1s/step - loss: 3.1485 - accuracy: 0.6546 - val_loss: 8.2788 - val_accuracy: 0.3619\n","Epoch 3/30\n","60/60 [==============================] - 80s 1s/step - loss: 2.4727 - accuracy: 0.6944 - val_loss: 6.6159 - val_accuracy: 0.3808\n","Epoch 4/30\n","60/60 [==============================] - 81s 1s/step - loss: 1.9776 - accuracy: 0.7144 - val_loss: 4.5897 - val_accuracy: 0.4874\n","Epoch 5/30\n","60/60 [==============================] - 83s 1s/step - loss: 1.9030 - accuracy: 0.7123 - val_loss: 3.3831 - val_accuracy: 0.5481\n","Epoch 6/30\n","60/60 [==============================] - 75s 1s/step - loss: 1.3765 - accuracy: 0.7458 - val_loss: 1.9861 - val_accuracy: 0.6987\n","Epoch 7/30\n","60/60 [==============================] - 77s 1s/step - loss: 1.4476 - accuracy: 0.7411 - val_loss: 8.4532 - val_accuracy: 0.2887\n","Epoch 8/30\n","60/60 [==============================] - 83s 1s/step - loss: 1.2864 - accuracy: 0.7589 - val_loss: 4.2668 - val_accuracy: 0.4958\n","Epoch 9/30\n","60/60 [==============================] - 79s 1s/step - loss: 1.2980 - accuracy: 0.7715 - val_loss: 4.2079 - val_accuracy: 0.5000\n","Epoch 10/30\n","60/60 [==============================] - 76s 1s/step - loss: 1.2585 - accuracy: 0.7699 - val_loss: 2.9552 - val_accuracy: 0.6088\n","Epoch 11/30\n","60/60 [==============================] - 75s 1s/step - loss: 1.3237 - accuracy: 0.7736 - val_loss: 4.4754 - val_accuracy: 0.4707\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fcff24f57f0>"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["# Entrenar el modelo con los datos de entrenamiento\n","model.fit(X_train_tf, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"5U_JFq4Icn41"},"outputs":[],"source":["# Guardar el modelo entrenado\n","model.save('modeloGuanacoIV3.h5')"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"9nvfONpccn42","outputId":"0cd326f7-cce5-48cd-dfd2-9cb58b58bf84"},"outputs":[{"name":"stdout","output_type":"stream","text":["14/14 [==============================] - 17s 1s/step\n"]}],"source":["y_proba = model.predict(X_test_tf)\n","y_pred = (y_proba >= 0.5).astype(int)"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"_Q68mlQScn42","outputId":"c79bc363-baf7-489c-f85b-d4e352b77d73"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.6235565819861432\n","Recall: 0.5420875420875421\n","Precision: 0.8563829787234043\n","Specificity: 0.8014705882352942\n"]}],"source":["# Calculamos Accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Calculamos Recall\n","recall = recall_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Recall: {recall}\")\n","\n","# Calculamos Precision\n","precision = precision_score(y_test, y_pred, pos_label=1, average='binary')\n","print(f\"Precision: {precision}\")\n","\n","# Calculamos Specificity\n","tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","specificity = tn / (tn + fp)\n","print(f\"Specificity: {specificity}\")\n","\n","# Accuracy: 0.74364896073903\n","# Recall: 0.9932659932659933\n","# Precision: 0.7301980198019802\n","# Specificity: 0.19852941176470587"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"XK62nQ-7cn42","outputId":"f5a9f6a9-0818-4e07-983a-c9301aa1c202"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Precision (AP): 0.7893658695225838\n"]}],"source":["# Calcular average precision\n","ap = average_precision_score(y_test, y_proba)\n","\n","print(\"Average Precision (AP):\", ap)"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"qIx71vHjcn43","outputId":"7309b0f9-19ab-4020-fdcb-9603a5717f9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","       False       0.36      0.86      0.51       138\n","        True       0.82      0.29      0.43       299\n","\n","    accuracy                           0.47       437\n","   macro avg       0.59      0.58      0.47       437\n","weighted avg       0.68      0.47      0.46       437\n","\n"]}],"source":["print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cm-lxoYicn43","outputId":"36c73d65-088d-4406-a7d4-9d8fd51708fc"},"outputs":[{"data":{"text/plain":["0.7780320366132724"]},"execution_count":352,"metadata":{},"output_type":"execute_result"}],"source":["(y_pred == 0).sum() / len(y_pred)"]},{"cell_type":"markdown","metadata":{"id":"5TkOE7uAcn43"},"source":["# Entrenamiento Categoria Especie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jcF5Mefcn43"},"outputs":[],"source":["# Carga la base de datos de Train y Test\n","train = pd.read_pickle('trainingCategoria.pkl')\n","test = pd.read_pickle('testingCategoria.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B8vlLXGwcn49"},"outputs":[],"source":["X_train = train['Imagen']\n","y_train = train['Categoria']\n","X_test = test['Imagen']\n","y_test = test['Categoria']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vHN3i8Dkcn49"},"outputs":[],"source":["# Convierte los datos de entrenamiento y etiquetas en tensores de TensorFlow\n","X_train_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_train]))\n","X_test_tf = tf.convert_to_tensor(np.array([img_to_array(img) for img in X_test]))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
